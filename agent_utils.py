
import os
import re
import json
import logging
import ast
import numpy as np
import cv2
from PIL import Image
import torch
from pathlib import Path

# ÂÖ®Â±ÄËÆäÊï∏‰Ωî‰ΩçÁ¨¶ (Â∞áÁî± app.py Ê≥®ÂÖ•)
DRUG_ALIASES = {}
DRUG_DATABASE = {}
_SYNTHETIC_DATA_GEN_SOURCE = {}
BLUR_THRESHOLD = 25.0  # [Red Team Fix] Lowered for handheld demo stability

# [V11.0] Layer 3: Safe Substrings (Whitelist for trusted meds)
# Fixes "Aspirin E.C." or "Panadol Extra" being flagged as Unknown
SAFE_SUBSTRINGS = ["aspirin", "bokey", "panadol", "acetaminophen", "warfarin", "coumadin", 
                   "metformin", "glucophage", "stilnox", "zolpidem", "plavix", "clopidogrel",
                   "diovan", "valsartan", "norvasc", "amlodipine", "concor", "bisoprolol",
                   "lasix", "furosemide", "lipitor", "atorvastatin", "crestor", "rosuvastatin",
                   "xanax", "alprazolam", "valium", "diazepam", "rivaroxaban", "xarelto"]

def get_environment():
    """
    üåç Áµ±‰∏ÄÁí∞Â¢ÉÂà§Êñ∑ (Environment Unification)
    Á¢∫‰øùÂÖ®Á≥ªÁµ±ÁöÑË∑ØÂæëËàáË°åÁÇ∫‰∏ÄËá¥
    """
    if os.path.exists("/kaggle/working"):
        return "KAGGLE"
    elif os.getenv("SPACE_ID"):
        return "HF_SPACE"
    else:
        return "LOCAL"

def extract_generic_from_context(full_data, drug_name_with_parentheses=None):
    """
    üß† Enhanced Context-Aware Drug Extraction (Round 120.1 Hardening)
    ÂæûÂ§öÂÄã‰æÜÊ∫êÊèêÂèñËó•Áâ©Â≠∏ÂêçÔºå‰ΩúÁÇ∫‰∫åÊ¨°È©óË≠â‰æÜÊ∫ê
    
    Á≠ñÁï•ÂÑ™ÂÖàÈ†ÜÂ∫èÔºö
    1. ÂæûËó•Áâ©ÂêçÁ®±ÁöÑÊã¨ËôüÂÖßÊèêÂèñÔºàÊúÄÂèØÈù†Ôºâ
    2. Âæû safety_analysis.reasoning ÊèêÂèñ
    3. ÂæûÂÆåÊï¥ VLM ÂéüÂßãËº∏Âá∫ÊñáÂ≠óÊèêÂèñÔºàÊúÄÂº∑ÂÅ•Ôºâ
    
    Args:
        full_data: ÂÆåÊï¥ÁöÑ VLM Ëº∏Âá∫Â≠óÂÖ∏
        drug_name_with_parentheses: Ëó•Áâ©ÂêçÁ®±ÔºàÂèØËÉΩÂåÖÂê´Êã¨ËôüÂ≠∏ÂêçÔºâ
    
    Returns:
        matched_generic: Âú®Ë≥áÊñôÂ∫´‰∏≠ÊâæÂà∞ÁöÑÂ≠∏ÂêçÔºåËã•ÁÑ°ÂâáËøîÂõû None
    """
    import re
    
    try:
        # Strategy 1: Extract from parentheses in drug name
        # Example: "Dilatrend 25mg (Carvedilol)" ‚Üí "Carvedilol"
        if drug_name_with_parentheses:
            paren_match = re.search(r'\(([^)]+)\)', drug_name_with_parentheses)
            if paren_match:
                potential_generic = paren_match.group(1).strip().lower()
                # Verify against database
                if DRUG_DATABASE:
                    for cat, items in DRUG_DATABASE.items():
                        for item in items:
                            if potential_generic == str(item.get("generic", "")).lower():
                                print(f"üîç [Parentheses Extraction] Found '{potential_generic}' ‚Üí {item['name_en']}")
                                return item["name_en"]
        
        # Strategy 2: Extract from safety_analysis.reasoning (original logic)
        reasoning = ""
        if isinstance(full_data, dict):
            safety = full_data.get("safety_analysis", {})
            if isinstance(safety, dict):
                reasoning = str(safety.get("reasoning", "")).lower()
        
        # Strategy 3: Fallback to full VLM output text (most robust)
        # VLM might output text like "Drug Dilatrend (Carvedilol)" outside JSON
        full_text = ""
        if isinstance(full_data, dict):
            # Try to get any text-based field that might contain drug info
            full_text = str(full_data).lower()
        
        # Combine all text sources
        combined_text = reasoning + " " + full_text
        
        if not combined_text.strip() or not DRUG_DATABASE:
            return None
        
        # Build candidate list
        generic_candidates = []
        for cat, items in DRUG_DATABASE.items():
            for item in items:
                generic = str(item.get("generic", "")).lower().strip()
                brand = str(item.get("name_en", "")).lower().strip()
                if generic and len(generic) > 3:
                    generic_candidates.append((generic, brand, item["name_en"]))
        
        # Search for generics in combined text
        for generic, brand_lower, brand_display in generic_candidates:
            # Precise word boundary match
            pattern = r'\b' + re.escape(generic) + r'\b'
            if re.search(pattern, combined_text, re.IGNORECASE):
                print(f"üß† [Context-Aware RAG] Extracted '{generic}' (‚Üí {brand_display}) from context")
                return brand_display
        
        return None
        
    except Exception as e:
        print(f"‚ö†Ô∏è [Context Extraction Error] {e}")
        return None


def bidirectional_rag_filter(drug_name):
    """
    üîç Bidirectional RAG Verification (Ghost Drug Filter)
    [Fixed] Â¢ûÂº∑Â∞ç OCR ÈõúË®äÁöÑÊäóÊÄßÔºåÈôç‰ΩéË™§ÊÆ∫Áéá
    """
    # üõ°Ô∏è [Round 120.4] Debug logging for Hydroxyzine bug
    DEBUG_VERBOSE = False  # Debugging complete

    
    if not drug_name or str(drug_name).lower() == "unknown":
        return True # È†êË®≠ÊîæË°å
        
    if not DRUG_DATABASE:
        if DEBUG_VERBOSE:
            print(f"‚ö†Ô∏è [RAG Filter] DRUG_DATABASE is empty! Allowing '{drug_name}'")
        return True # ÁÑ°Ë≥áÊñôÂ∫´ÂèØÊØîÂ∞çÔºåÁõ¥Êé•ÊîæË°å
    else:
        if DEBUG_VERBOSE:
            db_size = sum(len(items) for items in DRUG_DATABASE.values())
            print(f"üîç [RAG Filter] DB loaded ({db_size} drugs). Testing: '{drug_name}'")

    import difflib
    import re
    
    q_raw = str(drug_name).lower().strip()
    
    # [V11.2 Round 103] Proactive Whitelist check
    # Check global SAFE_SUBSTRINGS first to avoid RAG false positives for trusted meds
    if any(safe in q_raw for safe in SAFE_SUBSTRINGS):
        return True

    # üßπ 1. Ê∏ÖÁêÜÂ∏∏Ë¶ãÁöÑ OCR ÈõúË®äËàáÂäëÈáèÂñÆ‰Ωç (‰æãÂ¶Ç: "ËÑàÂÑ™Èå† 5mg" -> "ËÑàÂÑ™")
    q_clean = re.sub(r'\s*\d+\.?\d*\s*(mg|g|mcg|ug|ml|ÊØ´ÂÖã|ÂÖ¨ÂÖã|Èå†|È°Ü|Á≤í|capsule|tablet)s?\b', '', q_raw).strip()
    q_clean = re.sub(r'[\(\)\[\]ÔºàÔºâ]', '', q_clean).strip()

    if q_clean in DRUG_ALIASES or q_raw in DRUG_ALIASES:
        return True
        
    ARTIFACTS = ["step", "extraction", "think", "reason", "protocol", "json", "result", "analysis"]
    if any(art in q_clean for art in ARTIFACTS):
        return False # ÈÄôÊòØ AI ÁöÑÊÄùËÄÉÈõúË®äÔºåÊîîÊà™
        
    candidates = []
    for cat, items in DRUG_DATABASE.items():
        for item in items:
            candidates.extend([item['name_en'].lower(), item['name_zh'].lower(), item['generic'].lower()])
    
    # üü¢ 2. Â≠êÂ≠ó‰∏≤ÊØîÂ∞ç (Substring Match) - Âè™Ë¶ÅÊúâÂåÖÂê´Â∞±Áµ¶ÈÅé
    for c in candidates:
        if c and (c in q_clean or q_clean in c):
            return True
            
    # üü¢ 3. ÊîæÂØ¨Ê®°Á≥äÊØîÂ∞çÈñÄÊ™ª (0.85 -> 0.60)
    matches = difflib.get_close_matches(q_clean, candidates, n=1, cutoff=0.60)
    if len(matches) > 0:
        return True
        
    # üö® RAG Shield will be triggered (logging handled by neutralize_hallucinations)
    return False


def neutralize_hallucinations(data, context="", full_data=None):
    """
    ‚ò¢Ô∏è Ê†∏Á¥öÈò≤ÂπªË¶∫Ë≠∑Áõæ V3.2ÔºöÂºïÂÖ•ÈõôÂêë RAG È©óË≠â + Context-Aware Êô∫ËÉΩÈôçÁ¥ö
    [V3.1] ÊîØÊè¥ Context ÊÑüÁü•ÔºåÈÅøÂÖçË™§ÊÆ∫ÊÇ£ËÄÖÂßìÂêç
    [V3.2 Round 120] Âæû reasoning ÊèêÂèñÂ≠∏ÂêçÈÄ≤Ë°å‰∫åÊ¨°È©óË≠âÔºåÊ∏õÂ∞ëË™§Â†±
    
    Args:
        data: Ë¶ÅËôïÁêÜÁöÑË≥áÊñôÔºàÂ≠óÂÖ∏/ÂàóË°®/Âü∫Êú¨ÂûãÂà•Ôºâ
        context: Áï∂ÂâçËôïÁêÜÁöÑ‰∏ä‰∏ãÊñáÔºà"patient_scope" Á≠âÔºâ
        full_data: ÂÆåÊï¥ÁöÑ VLM Ëº∏Âá∫ÔºàÁî®ÊñºÊèêÂèñ reasoningÔºâ
    """
    # üõ°Ô∏è [POC / DEMO ONLY] Èö±ÁßÅË≠∑Áõæ (Privacy Shield) Ê¶ÇÂøµÈ©óË≠â
    # Á´∂Ë≥ΩÂ±ïÁ§∫Â∞àÁî®ÔºöÊ≠§Ëôï‰ΩøÁî®ÈùúÊÖãÈô£ÂàóÊîîÊà™ÁâπÂÆöÁöÑÊ∏¨Ë©¶Ë≥áÊñôÂÄãË≥á‰ª•Èò≤Ê≠¢Â§ñÊ¥©„ÄÇ
    # ÊñºÁúüÂØ¶Áî¢ÂìÅÁí∞Â¢É (Production) ‰∏≠ÔºåÊ≠§Ê®°ÁµÑÂ∞á‰∏≤Êé•Ê≠£Ë¶èÁöÑ Medical NER (ÂëΩÂêçÂØ¶È´îËæ®Ë≠ò) Ê®°ÂûãÔºå
    # Ëá™ÂãïË≠òÂà•‰∏¶ÈÅÆËîΩÊâÄÊúâÊú™Áü•ÁöÑÁóÖÊÇ£ÂßìÂêç (Name) ËàáÂπ¥ÈΩ° (Age)„ÄÇ
    BANNED_NAMES = ["ÂäâÊ∑ëËä¨", "ÁéãÂ§ßÊòé", "Èô≥Â∞èÊòé"]
    BANNED_AGES = ["79", "83", "88"]
    
    if isinstance(data, dict):
        new_data = {}
        for k, v in data.items():
            val_str = str(v).strip()
            
            # ÂÖàËôïÁêÜÈÅûËø¥
            if isinstance(v, (dict, list)):
                # üü¢ [Fix] Â¶ÇÊûúÁï∂Ââç key ÊòØ patientÔºåÊ®ôË®ò context ÁÇ∫ "patient_scope"
                new_context = "patient_scope" if k == "patient" else context
                # üß† [V3.2] Âêë‰∏ãÂÇ≥ÈÅû full_data ‰ª•ÊîØÊè¥ context-aware ÊèêÂèñ
                new_data[k] = neutralize_hallucinations(v, context=new_context, full_data=full_data or data)
                continue

            # 1. Èö±ÁßÅ‰∏≠Âíå (ÂßìÂêç/Âπ¥ÈΩ°) - [Round 128 Polish]
            if k in ["name", "detected_name"] and val_str in BANNED_NAMES:
                 # Only neutralize if it's a known test-data dummy that indicates extraction failure
                 print(f"üõ°Ô∏è [Shield] Hallucination Detected (Banned Name): {v} -> Neutralized to Unknown")
                 new_data[k] = "Unknown"
            elif k == "age" and val_str in BANNED_AGES:
                 print(f"üõ°Ô∏è [Shield] Hallucination Detected (Banned Age): {v} -> Neutralized to Unknown")
                 new_data[k] = "Unknown"
            
            # 2. ÈõôÂêë RAG È©óË≠â (ÂπΩÈùàËó•ÂìÅÈÅéÊøæ) + Êô∫ËÉΩÈôçÁ¥ö
            elif k in ["name", "drug_name", "drug", "zh", "generic"]:
                # üü¢ [Fix] Â¶ÇÊûúË∫´Ëôï patient_scopeÔºåË∑≥ÈÅé RAG Ê™¢Êü•
                if context == "patient_scope":
                    new_data[k] = v
                elif not bidirectional_rag_filter(val_str):
                    # üß† [V3.2] Êô∫ËÉΩÈôçÁ¥öÔºöÂòóË©¶Â§öÈáçÁ≠ñÁï•ÊèêÂèñÂ≠∏Âêç
                    contextual_match = None
                    if full_data:
                        # Pass the drug name itself for parentheses extraction
                        contextual_match = extract_generic_from_context(
                            full_data, 
                            drug_name_with_parentheses=val_str
                        )
                    
                        # Case A: Âú® context ‰∏≠ÊâæÂà∞Â∑≤Áü•Ëó•Áâ©Â≠∏Âêç
                        print(f"üîç [Smart Degradation] '{val_str}' ‚Üí Likely '{contextual_match}' (via context)")
                        new_data[k] = f"‚ö†Ô∏èÊé®Ê∏¨ÁÇ∫: {contextual_match} (Êú™È©óË≠â)"
                    else:
                        # Case B: ÁúüÊ≠£ÁöÑÊú™Áü•Ëó•Áâ© - ËªüÊÄßÊ®ôË®ò‰øùÁïô
                        print(f"‚ö†Ô∏è [RAG] Êú™Áü•Ëó•Áâ©‰øùÁïô: {val_str}")
                        new_data[k] = f"{v} (‚ö†Ô∏èË≥áÊñôÂ∫´Êú™Êî∂ÈåÑ)"
                else:
                    new_data[k] = v
            else:
                new_data[k] = v
        return new_data
    
    elif isinstance(data, list):
        return [neutralize_hallucinations(item, context, full_data=full_data) for item in data]
    
    return data

def calculate_confidence(model, outputs, processor):
    """
    Entropy-aware Confidence Calculation
    """
    try:
        transition_scores = model.compute_transition_scores(
            outputs.sequences, outputs.scores, normalize_logits=True
        )
        probs = torch.exp(transition_scores)
        min_prob = probs.min().item()
        mean_prob = probs.mean().item()
        alpha = 0.75
        return (mean_prob * alpha) + (min_prob * (1 - alpha))
    except:
        return 0.0

def get_confidence_status(confidence, predicted_status="UNKNOWN", custom_threshold=None):
    """
    Dynamic Thresholding
    """
    if custom_threshold is not None:
        threshold = custom_threshold
    else:
        # [V1.0 Impact] Dual-Threshold System: Recall for Risk (0.50), Precision for Safety (0.70)
        threshold = 0.50 if predicted_status in ["HIGH_RISK", "PHARMACIST_REVIEW_REQUIRED"] else 0.70
        
    if confidence >= threshold:
        return "HIGH_CONFIDENCE", f"‚úÖ Conf: {confidence:.1%} (Th: {threshold})"
    return "LOW_CONFIDENCE", f"‚ö†Ô∏è Unsure ({confidence:.1%}) -> ESCALATE"

# ÂÖ®Â±Ä OCR ÂºïÊìé (Êá∂Âä†Ëºâ)
OCR_READER = None 

_UNIFIED_RAG_INSTANCE = None

def resolve_drug_name_zh(raw_name):
    """
    Â∞áËã±ÊñáËó•ÂêçÂ∞çÁÖßË≥áÊñôÂ∫´ËΩâÊèõÁÇ∫‰∏≠ÊñáËó•Âêç (Localization Support)
    """
    if not raw_name or raw_name == "Êú™Áü•Ëó•Áâ©":
        return raw_name
    
    # Ê∏ÖÁêÜÂêçÁ®± (ÁßªÈô§ÂäëÈáèËàáÊã¨ËôüÈõúË®äÔºå‰æãÂ¶Ç "Norvasc 5mg" -> "norvasc")
    clean_name = re.sub(r'\s*\d+\.?\d*\s*(mg|g|mcg|ug|ml|ÊØ´ÂÖã|ÂÖ¨ÂÖã)\b', '', str(raw_name), flags=re.IGNORECASE)
    clean_name = re.sub(r'\s*\([^)]*\)', '', clean_name).strip().lower()
    
    # 1. Áõ¥Êé•ÂëΩ‰∏≠Âà•Âêç
    target = DRUG_ALIASES.get(clean_name, clean_name)
    
    # 2. ÈÅçÊ≠∑Ë≥áÊñôÂ∫´ÈÄ≤Ë°åÂåπÈÖç
    if DRUG_DATABASE:
        best_match = None
        best_score = 0
        
        for category in DRUG_DATABASE.values():
            for item in category:
                # ÂÆåÊï¥ÂåπÈÖçËã±ÊñáÂêçÊàñÈÄöÁî®Âêç
                if target in [item['name_en'].lower(), item['generic'].lower()]:
                    return item['name_zh']
                
                # Ê®°Á≥äÂåπÈÖç (ÈáùÂ∞ç OCR Ë™§ÂÇ≥ÔºåÂ¶Ç Aspirinh -> Aspirin)
                # ‰ΩøÁî®Á∞°ÂñÆÁöÑÂ≠óÂÖÉÈáçÂêàÂ∫¶Êàñ difflib
                from difflib import SequenceMatcher
                for candidate in [item['name_en'].lower(), item['generic'].lower()]:
                    score = SequenceMatcher(None, target, candidate).ratio()
                    if score > 0.85 and score > best_score:
                        best_score = score
                        best_match = item['name_zh']

                # ÈóúÈçµÂ≠óÂåÖÂê´ÂåπÈÖç (‰æãÂ¶Ç VLM ÂêêÂá∫ "Glucophage Tablets")
                # [Integrity Fix] ÊèêÈ´òÂ≠êÂ≠ó‰∏≤ÊØîÂ∞çÂö¥Ê†ºÂ∫¶ÔºåÈò≤Ê≠¢ short-string Ë™§Â†± (‰æãÂ¶Ç "the" -> "Metformin")
                if clean_name and len(clean_name) >= 5 and (clean_name in item['name_en'].lower() or item['name_en'].lower() in clean_name):
                    return item['name_zh']
        
        # Â¶ÇÊûúÊ®°Á≥äÂåπÈÖçÂàÜÊï∏Â§†È´òÔºåÂâáÊé°Áî®
        if best_match and best_score > 0.85:
            print(f"üõ°Ô∏è [Fuzzy Fix] {raw_name} -> {best_match} (Score: {best_score:.2f})")
            return best_match
                
    return raw_name # Êâæ‰∏çÂà∞ÂâáÂõûÂÇ≥ÂéüÂßãÂêçÁ®± (Ëá≥Â∞ëÊúâÂéüÂßãË≥áË®ä)

def get_rag_engine():
    """Singleton for the Unified RAG Engine."""
    global _UNIFIED_RAG_INSTANCE
    if _UNIFIED_RAG_INSTANCE is None:
        _UNIFIED_RAG_INSTANCE = UnifiedRAGEngine()
    return _UNIFIED_RAG_INSTANCE

class UnifiedRAGEngine:
    """
    üß† Unified RAG Engine (V10.0 Integrated)
    Combines: Vector Search (High Precision) + Fuzzy Match (Robust Fallback)
    """
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(UnifiedRAGEngine, cls).__new__(cls)
            cls._instance.initialized = False
        return cls._instance

    def __init__(self):
        if self.initialized: return
        self.vector_engine = None
        self.rag_available = False

        self.initialized = True
        self.index = None
        self.drug_database = {}
        self.fuzzy_cache = {"candidates": [], "lookup": {}}
        self._needs_fuzzy_rebuild = True
        self._setup_vector_if_possible()

    def inject_data(self, db):
        """Inject drug database and trigger rebuild of cache."""
        # üü¢ [Fix] Handle empty DB gracefully
        if not db: 
            self.drug_database = {}
            self._needs_fuzzy_rebuild = True  # Force rebuild to clear cache
            print("‚ö†Ô∏è [RAG] Empty database injected. Cache cleared.")
            return

        self.drug_database = db
        # Also sync global DRUG_DATABASE for other components
        global DRUG_DATABASE
        DRUG_DATABASE = db
        self._needs_fuzzy_rebuild = True
        
        # ‚úÖ [Round 121 Fix] Ë®àÁÆóÂØ¶ÈöõËó•Áâ©Á∏ΩÊï∏
        total_drugs = sum(len(items) for items in db.values() if isinstance(items, list))
        print(f"üìä [RAG] Data injected: {len(db)} categories, {total_drugs} total drugs")

    def _rebuild_fuzzy_cache(self):
        """Build candidates and lookup for fuzzy matching."""
        candidates = []
        lookup = {}
        db = self.drug_database or DRUG_DATABASE
        
        # ‚úÖ [Round 122 Fix] ÊòéÁ¢∫ËôïÁêÜÂ≠óÂÖ∏ÁµêÊßãÔºåÁ¢∫‰øùÈÅçÊ≠∑ÊâÄÊúâËó•Áâ©
        all_items = []
        if isinstance(db, dict):
            # ÈÅçÊ≠∑ÊâÄÊúâÂàÜÈ°ûÁöÑËó•Áâ©ÂàóË°®
            for category_items in db.values():
                if isinstance(category_items, list):
                    all_items.extend(category_items)
        elif isinstance(db, list):
            all_items = db
        else:
            print(f"‚ö†Ô∏è [RAG] Unexpected database type: {type(db)}")
            all_items = []
        
        # Âª∫Á´ãÊêúÂ∞ãÁ¥¢Âºï
        for item in all_items:
            en = item.get('name_en', '').lower()
            gen = item.get('generic', '').lower()
            zh = item.get('name_zh', '').lower()
            if en: 
                candidates.append(en)
                lookup[en] = item
            if gen: 
                candidates.append(gen)
                lookup[gen] = item
            if zh:
                candidates.append(zh)
                lookup[zh] = item
        
        # ‚úÖ [Round 121 Fix] Ê∑ªÂä†Ë©≥Á¥∞ËºâÂÖ•Êó•Ë™å
        total_drugs = len(all_items)
        total_categories = len(db) if isinstance(db, dict) else 0
        print(f"üìä [RAG Cache] Rebuilt: {total_categories} categories, {total_drugs} drugs, {len(candidates)} searchable terms")
        
        self.fuzzy_cache = {"candidates": candidates, "lookup": lookup}
        self._needs_fuzzy_rebuild = False

    def _setup_vector_if_possible(self):
        try:
            import faiss
            from sentence_transformers import SentenceTransformer
            # Note: We use a lightweight model for vector RAG
            self.rag_available = True
            print("üöÄ [RAG] Vector Search enabled (FAISS).")
        except ImportError:
            self.rag_available = False
            print("‚ö†Ô∏è [RAG] Vector dependencies missing. Falling back to Fuzzy logic.")


    def query(self, q, k=1):
        """Query the knowledge base."""
        # 1. Check for need to rebuild cache
        if self._needs_fuzzy_rebuild:
            self._rebuild_fuzzy_cache()

        # Check if Vector RAG is available and index is loaded
        if self.rag_available and self.index:
             # Strategy 1: Vector Search (Conceptual / Lazy Load)
             # [Future Implementation]
             pass

        # Strategy 2: Fuzzy Match (Canonical Fallback)
        import difflib
        q_lower = str(q).lower()
        candidates = self.fuzzy_cache["candidates"]
        lookup = self.fuzzy_cache["lookup"]
        
        if not candidates:
            return None, 1.0

        matches = difflib.get_close_matches(q_lower, candidates, n=1, cutoff=0.85) # ‚úÖ ÊèêÈ´òÂà∞ 0.85 (Safety First)
        if matches:
            match_key = matches[0]
            info = lookup.get(match_key, {})
            k_result = (f"Official Name: {info.get('name_en')}\n"
                        f"Generic: {info.get('generic')}\n"
                        f"Indication: {info.get('indication')}\n"
                        f"Standard Dose: {info.get('dose')}\n"
                        f"Warning: {info.get('warning')}\n"
                        f"Usage: {info.get('default_usage')}")
            dist = 1.0 - difflib.SequenceMatcher(None, q_lower, match_key).ratio()
            return k_result, dist
        
        return None, 1.0

    def get_drug_data(self, q):
        """Returns the raw drug dictionary for compatibility with app.py."""
        if self._needs_fuzzy_rebuild:
            self._rebuild_fuzzy_cache()

        import difflib
        q_lower = str(q).lower()
        candidates = self.fuzzy_cache["candidates"]
        lookup = self.fuzzy_cache["lookup"]
        
        if not candidates:
            return {"found": False, "name_en": q, "warning": "‚ö†Ô∏è Database Empty.", "risk": "UNKNOWN_DRUG"}

        # Exact check
        if q_lower in lookup:
            return {**lookup[q_lower], "found": True, "match_type": "EXACT"}

        # Substring check (V15 Feature: ÊèêÂçáÊØîÂ∞çÂØ¨ÂÆπÂ∫¶)
        # Fixes: "ÈòøÊñØÂåπÈùà" vs "‰ºØÂü∫/ÈòøÊñØÂåπÈùà"
        for candidate, info in lookup.items():
            if len(q_lower) >= 2 and (q_lower in candidate or candidate in q_lower):
                return {**info, "found": True, "match_type": "SUBSTRING"}

        # Fuzzy check
        matches = difflib.get_close_matches(q_lower, candidates, n=1, cutoff=0.8)
        if matches:
            match_key = matches[0]
            info = lookup.get(match_key, {})
            sim = difflib.SequenceMatcher(None, q_lower, match_key).ratio()
            return {**info, "found": True, "match_type": f"FUZZY ({sim:.2f})"}
            
        return {
            "found": False, 
            "class": "Unknown", 
            "name_en": q,
            "warning": "‚ö†Ô∏è UNKNOWN DRUG DETECTED. SYSTEM CANNOT VERIFY SAFETY.",
            "risk": "UNKNOWN_DRUG"
        }

def retrieve_drug_info(drug_name):
    """
    [Unification Wrapper]
    Enables app.py and agent_engine.py to use the singleton RAG engine 
    with a consistent dictionary output.
    """
    return get_rag_engine().get_drug_data(drug_name)

def check_image_quality(image_path):
    """
    üîç Input Validation Gate (Blur Detection + Size Check)
    Returns: (is_valid, quality_score, message)
    """
    try:
        # Handle numpy array (from Gradio) or file path
        if isinstance(image_path, str):
            img = cv2.imread(image_path)
        elif isinstance(image_path, Path):
            img = cv2.imread(str(image_path))
        elif isinstance(image_path, np.ndarray):
            img = image_path
        else:
            return False, 0.0, "ÁÑ°ÊïàÁöÑÂΩ±ÂÉèÊ†ºÂºè"

        if img is None:
            return False, 0.0, "ÁÑ°Ê≥ïËÆÄÂèñÂΩ±ÂÉèÊ™îÊ°à"
        
        # 1. Blur Detection (Laplacian Variance)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # 2. Size Check
        h, w = img.shape[:2]
        if w < 200 or h < 200:
            return False, laplacian_var, f"ÂΩ±ÂÉèÂ∞∫ÂØ∏ÈÅéÂ∞è ({w}x{h})"
        
        # 3. Threshold Check (BLUR_THRESHOLD defined globally in utils)
        # Using a safer local default if global is missing
        threshold = globals().get('BLUR_THRESHOLD', 25.0) 
        
        if laplacian_var < threshold:
            return False, laplacian_var, f"ÂΩ±ÂÉèÊ®°Á≥ä (ÂàÜÊï∏: {laplacian_var:.1f} < {threshold})"
        
        return True, laplacian_var, "ÂΩ±ÂÉèÂìÅË≥™ËâØÂ•Ω"
        
    except Exception as e:
        print(f"‚ö†Ô∏è Image Check Error: {e}")
        return True, 100.0, "ÂìÅË≥™Ê™¢Êü•Ë∑≥ÈÅé (Error)" # Fail open for demo stability

def clean_text_for_tts(text, lang='zh-tw'):
    """
    üîä [V15.0] Robust TTS Text Cleaner (Medical Jargon to Elder-Friendly Language)
    1. Removes JSON artifacts and special characters.
    2. Translates medical English abbreviations to target language.
    3. Filters out internal reasoning artifacts (Step 1, Reasoning, etc.).
    4. Normalizes units for clearer speech.
    """
    if not text:
        return ""
    
    import re
    text = str(text)

    # --- 1. Filter out internal Reasoning/CoT Artifacts ---
    # These often leak into LLM messages (e.g., "Step 1: ...")
    noise_patterns = [
        r'Step\s*\d+[:\-.]?', r'Reasoning[:\-.]?', r'Assessment[:\-.]?',
        r'Confidence[:\-.]?', r'Grounding[:\-.]?', r'Status[:\-.]?',
        r'Patient[:\-.]?', r'Drug[:\-.]?', r'Extracted[:\-.]?',
        r'Analysis[:\-.]?'
    ]
    for pattern in noise_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)

    # --- 2. Medical Jargon Translation Map (Elder-Friendly) ---
    # Note: Focus on abbreviations commonly found in "Usage" fields
    JARGON_MAP = {
        # Latin Abbreviations
        r'\bQD\b': '‰∏ÄÂ§©ÂêÉ‰∏ÄÊ¨°',
        r'\bBID\b': '‰∏ÄÂ§©ÂêÉÂÖ©Ê¨°',
        r'\bTID\b': '‰∏ÄÂ§©ÂêÉ‰∏âÊ¨°',
        r'\bQID\b': '‰∏ÄÂ§©ÂêÉÂõõÊ¨°',
        r'\bHs\b': 'Áù°ÂâçÂêÉ',
        r'\bQHS\b': 'Áù°ÂâçÂêÉ',
        r'\bPRN\b': 'Âæà‰∏çËàíÊúçÁöÑÊôÇÂÄôÊâçÂêÉ',
        r'\bac\b': 'È£ØÂâçÂêÉ',
        r'\bpc\b': 'È£ØÂæåÂêÉ',
        r'\bPO\b': 'Âè£Êúç',
        r'\bSTAT\b': 'Á´ãÂàªÂêÉ',
        r'\bq6h\b': 'ÊØèÂÖ≠ÂÄãÂ∞èÊôÇÂêÉ‰∏ÄÊ¨°',
        r'\bq8h\b': 'ÊØèÂÖ´ÂÄãÂ∞èÊôÇÂêÉ‰∏ÄÊ¨°',
        r'\bq12h\b': 'ÊØèÂçÅ‰∫åÂÄãÂ∞èÊôÇÂêÉ‰∏ÄÊ¨°',
        
        # Common English placeholders
        r'\bas\s+directed\b': 'ÁÖßÈÜ´ÁîüÁöÑÂê©ÂíêÂêÉ',
        r'\bas\s*needed\b': '‰∏çËàíÊúçÁöÑÊôÇÂÄôÊâçÂêÉ',
        
        # Units (to avoid speech engines saying "m-g")
        r'\bmg\b': 'ÊØ´ÂÖã',
        r'\bml\b': 'ÊØ´Âçá',
        r'\bkg\b': 'ÂÖ¨Êñ§',
        
        # --- Standard Taiwan Normalization (Elder-Friendly via Clarity) ---
        r'(\d)\s*Ê¨°': r'\1Ê¨°',
        r'1Ê¨°': '‰∏ÄÊ¨°',
        r'2Ê¨°': 'ÂÖ©Ê¨°',
        r'3Ê¨°': '‰∏âÊ¨°',
        r'4Ê¨°': 'ÂõõÊ¨°',
        r'1È°Ü': '‰∏ÄÈ°Ü',
        r'2È°Ü': 'ÂÖ©È°Ü',
        r'3È°Ü': '‰∏âÈ°Ü',
        r'4È°Ü': 'ÂõõÈ°Ü',
        r'1Èå†': '‰∏ÄÈå†', # Restore Èå†
        r'2Èå†': 'ÂÖ©Èå†',
        r'3Èå†': '‰∏âÈå†',
        r'4Èå†': 'ÂõõÈå†',
    }
    
    # ÈáùÂ∞çÂ§öÂúãË™ûË®ÄÂèØ‰ª•Êì¥ÂÖÖÊ≠§ Map (ÁõÆÂâçÈ†êË®≠ÊîØÊè¥‰∏≠Ëã±Ê∑∑ËÆÄÂÑ™Âåñ)
    for eng, local in JARGON_MAP.items():
        text = re.sub(eng, local, text, flags=re.IGNORECASE)

    # --- 3. UI/Markdown Artifact Removal ---
    # Remove JSON syntax
    text = re.sub(r'[{}"\[\]]', '', text)
    # Remove URLs
    text = re.sub(r'http[s]?://\S+', '', text)
    # Remove Markdown bold/italic
    text = re.sub(r'[*_#]', '', text)
    # Remove Emojis & excessive symbols (to prevent engine stutters)
    text = re.sub(r'[‚ö†Ô∏è‚úÖüî¥üü°üü¢‚ùìüö®‚õîüö´]', '', text)
    
    # Final cleanup of spacing
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()

def check_drug_interaction(drug_a, drug_b):
    """
    üîç Offline Drug Interaction Check (Local Knowledge Graph)
    """
    if not drug_a or not drug_b or "Êú™Áü•" in str(drug_a) or "Êú™Áü•" in str(drug_b):
        return "‚ö†Ô∏è Ë´ãËº∏ÂÖ•ÊúâÊïàÁöÑËó•ÂìÅÂêçÁ®±"
    
    # High-risk interaction pairs (Hardcoded Safety Rules)
    HIGH_RISK_PAIRS = {
        ("warfarin", "aspirin"): "‚ùå È´òÈ¢®Èö™ÔºÅÂÖ©Á®ÆÊäóÂáùË°ÄËó•‰ΩµÁî®ÊúÉÂ§ßÂπÖÂ¢ûÂä†Âá∫Ë°ÄÈ¢®Èö™",
        ("warfarin", "plavix"): "‚ùå È´òÈ¢®Èö™ÔºÅÂÖ©Á®ÆÊäóÂáùË°ÄËó•‰ΩµÁî®ÊúÉÂ§ßÂπÖÂ¢ûÂä†Âá∫Ë°ÄÈ¢®Èö™",
        ("aspirin", "plavix"): "‚ö†Ô∏è Ë≠¶ÂëäÔºöÈõôÈáçÊäóË°ÄÂ∞èÊùøËó•Áâ©ÈúÄÈÜ´Â∏´Ë©ï‰º∞",
        ("metformin", "glibenclamide"): "‚ö†Ô∏è Ê≥®ÊÑèÔºöÂÖ©Á®ÆÈôçË°ÄÁ≥ñËó•‰ΩµÁî®ÈúÄÁõ£Ê∏¨‰ΩéË°ÄÁ≥ñ",
        ("panadol", "alcohol"): "‚ùå Âç±Èö™ÔºÅÊôÆÊãøÁñºÈÖçÈÖíÊúÉÈÄ†ÊàêËÇùËáüÊêçÂÇ∑"
    }
    
    # Normalize drug names
    a_lower = str(drug_a).lower().strip()
    b_lower = str(drug_b).lower().strip()
    
    # Check both orderings
    pair1 = (a_lower, b_lower)
    pair2 = (b_lower, a_lower)
    
    if pair1 in HIGH_RISK_PAIRS:
        return f"üö® **‰∫§‰∫í‰ΩúÁî®Ë≠¶Á§∫**\n\n{HIGH_RISK_PAIRS[pair1]}\n\nÂª∫Ë≠∞ÔºöË´ÆË©¢ÈÜ´Â∏´ or Ëó•Â∏´"
    elif pair2 in HIGH_RISK_PAIRS:
        return f"üö® **‰∫§‰∫í‰ΩúÁî®Ë≠¶Á§∫**\n\n{HIGH_RISK_PAIRS[pair2]}\n\nÂª∫Ë≠∞ÔºöË´ÆË©¢ÈÜ´Â∏´ or Ëó•Â∏´"
    
    return f"‚úÖ **Èõ¢Á∑öÊ™¢Êü•ÁµêÊûú**\n\n{drug_a} Ëàá {drug_b} Âú®Êú¨Âú∞Ë≥áÊñôÂ∫´‰∏≠Êú™ÁôºÁèæÂ∑≤Áü•ÁöÑÂö¥Èáç‰∫§‰∫í‰ΩúÁî®„ÄÇ\n\n‚ö†Ô∏è Ê≥®ÊÑèÔºöÊ≠§ÁÇ∫Èõ¢Á∑öÊ™¢Êü•ÔºåÂª∫Ë≠∞‰ªçË´ÆË©¢Â∞àÊ•≠Ëó•Â∏´„ÄÇ"

def parse_json_from_response(response_text):
    """
    V7.0 Robust Parser: Native json.loads with Regex Extraction
    Supports: null, true, false, and multi-line structures
    """
    if not response_text:
        return None, "Empty response"
        
    try:
        # 1. ÂòóË©¶ÊèêÂèñ markdown ÂçÄÂ°äÂÖßÁöÑ JSON (‰ΩøÁî® re.DOTALL Á¢∫‰øùË∑®Ë°åÂåπÈÖç)
        match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
        json_str = match.group(1) if match else response_text

        # 2. ÁµÇÊ•µÈò≤Á∑öÔºöÂ¶ÇÊûú VLM ÂøòË®òÂØ´ÂæåÈù¢ÁöÑ ```ÔºåÁõ¥Êé•ÊäìÂèñÁ¨¨‰∏ÄÂ∞çÂ§ßÊã¨Ëôü (Greedy Match)
        if not match:
            match_bracket = re.search(r'\{.*\}', json_str, re.DOTALL)
            if match_bracket:
                json_str = match_bracket.group(0)

        # 3. Ê∏ÖÁêÜËàáËß£Êûê (ÂéüÁîüÊîØÊè¥ true/false/null)
        json_str = json_str.strip()
        data = json.loads(json_str)
        
        # [V27 Fix] Unwrap "parsed" if model nested it
        if "parsed" in data and isinstance(data["parsed"], dict):
            data = data["parsed"]
        return data, None
        
    except Exception as e:
        # Strategy 2: Fallback to literal_eval for single quote messes (legacy support)
        try:
            # ÊõøÊèõÁÇ∫ Python Ë™ûÊ≥ï
            eval_str = json_str.replace("true", "True").replace("false", "False").replace("null", "None")
            data = ast.literal_eval(eval_str)
            if isinstance(data, dict):
                if "parsed" in data and isinstance(data["parsed"], dict):
                    data = data["parsed"]
                return data, None
        except:
            pass
            
        print(f"‚ö†Ô∏è JSON Ëß£ÊûêÂ§±Êïó: {e}\nÂéüÂßãÊñáÂ≠óÁâáÊÆµ: {response_text[:100]}...")
        return None, f"Parsing failed: {str(e)}"

def normalize_dose_to_mg(dose_str):
    """
    üß™ [Canonical] Normalize raw dosage string to milligrams (mg)
    Handles: "500 mg", "0.5 g", "1000 mcg"
    Returns: (list_of_mg_values, is_valid_conversion)
    """
    if not dose_str: return [], False
    s_full = str(dose_str).lower().replace(",", "").replace(" ", "")
    parts = re.split(r'[/\+]', s_full)
    results = []
    for s in parts:
        if not s: continue
        try:
            # [P0 Fix] Âä†ÂÖ• È°Ü/Èå†/Á≤í/tablet/capsule ÁöÑËæ®Ë≠ò
            match = re.search(r'([\d\.]+)(mg|g|mcg|ug|ml|ÊØ´ÂÖã|ÂÖ¨ÂÖã|È°Ü|Èå†|Á≤í|tablet|capsule)', s)
            val = 0.0
            if not match:
                 nums = re.findall(r'\d*\.?\d+', s)
                 if nums: 
                     val_candidates = [float(n) for n in nums]
                     val = max(val_candidates)
                     is_decimal = (val % 1 != 0)
                     high_risk_keywords = ["warfarin", "glimepiride", "bisoprolol", "coumadin", "mg"]
                     is_likely_dose = any(k in s.lower() for k in high_risk_keywords)
                     if val < 10 and not is_decimal and not is_likely_dose: 
                         continue 
                 else:
                     continue
            else:
                val = float(match.group(1))
                unit = match.group(2)
                if unit in ['g', 'ÂÖ¨ÂÖã']: val *= 1000.0
                elif unit in ['mcg', 'ug']: val /= 1000.0
                elif unit in ['È°Ü', 'Èå†', 'Á≤í', 'tablet', 'capsule']:
                    # [V1.7 Precision Fix] ÁßªÈô§ 9999.0 Êö¥Ëµ∞ÈÇèËºØ„ÄÇ
                    # Âè™ÊèêÂèñÊï∏ÂÄºÔºåË®àÁÆó‰∫§Áµ¶ÂæåÁ∫åÁöÑ fallback Êàñ hard rule ËôïÁêÜÔºåÈÅøÂÖçË™§Â†±„ÄÇ
                    continue 
            results.append(val)
        except: continue
    
    # [V1.7 Precision Fix] ÂæπÂ∫ïÁßªÈô§ multiplier_match (5X, 10X) ÈÇèËºØÔºåÈÅøÂÖçËàáÈ†ªÁéá (2 times) Ê∑∑Ê∑Ü„ÄÇ
    return results, bool(results)
            
    return results, bool(results)

def check_hard_safety_rules(extracted_data, voice_context=""):
    """
    [Canonical] Centralized Hard Rule Engine (Single Source of Truth)
    Returns: (is_triggered, status, reasoning)
    """
    try:
        actual_data = extracted_data
        if "extracted_data" in extracted_data and isinstance(extracted_data["extracted_data"], dict):
            actual_data = extracted_data["extracted_data"]
            
        patient = actual_data.get("patient", {}) if isinstance(actual_data.get("patient"), dict) else {}
        drug = actual_data.get("drug", {}) if isinstance(actual_data.get("drug"), dict) else {}
        raw_drug_name = drug.get("name") or actual_data.get("drug_name") or ""
        raw_drug_zh = drug.get("name_zh") or ""
        drug_name = (str(raw_drug_name).lower() + " " + str(raw_drug_zh).lower()).strip()
        raw_age = patient.get("age") or actual_data.get("patient_age") or "0"
        
        # üõ°Ô∏è [Hardening] ÂÆâÂÖ®ÊèêÂèñÂπ¥ÈΩ°Êï∏Â≠óÔºåÈò≤Á¶¶ "82Ê≠≤" Êàñ "" Á≠âÁï∞Â∏∏Â≠ó‰∏≤
        age_str = str(raw_age)
        age_digits = re.sub(r'\D', '', age_str)
        try:
            age_val = int(age_digits) if age_digits else 0
        except:
            age_val = 0 # Á¢∫‰øùÂ¥©ÊΩ∞ÊôÇÈÄÄÂõûÂà∞ 0ÔºåËß∏Áôº MISSING_DATA ÊîîÊà™
            
        # üõ°Ô∏è [FAIL-SAFE] Check for missing age on high-risk geriatric drugs
        # Â¶ÇÊûúÂπ¥ÈΩ°ÁÇ∫ 0 (Ëß£ÊûêÂ§±ÊïóÊàñÊºèÂ§±)ÔºåÈáùÂ∞ç Beers Criteria È´òÈ¢®Èö™Ëó•Áâ©Âº∑Âà∂ÊîîÊà™
        if age_val == 0:
            high_risk_elderly_drugs = ["aspirin", "bokey", "zolpidem", "stilnox", "metformin", "glucophage"]
            if any(d in drug_name for d in high_risk_elderly_drugs):
                return True, "MISSING_DATA", "‚õî HARD RULE: Ê≠§Ëó•Áâ©Â∞çÈ´òÈΩ°ËÄÖÊúâÈ´òÂ∫¶È¢®Èö™Ôºå‰ΩÜÁ≥ªÁµ±ÁÑ°Ê≥ïËÆÄÂèñÊàñÁº∫‰πèÁóÖÊÇ£Âπ¥ÈΩ°Ë≥áÊñôÔºåÂü∫ÊñºÂÆâÂÖ®ËÄÉÈáèÂº∑Âà∂ÈÄÄÂõû‰∫∫Â∑•Ê†∏Â∞ç„ÄÇ"
            
        # üõ°Ô∏è [RED TEAM FIX] Ë™ûÈü≥Âá∫Ë°ÄË≠∑Ê¨Ñ (Voice Guardrail)
        # ---------------------------------------------------------
        # üè• [V1.7 Clinical Awareness] ICD-10 ËàáÁóÖÂè≤Ë≠òÂà• (‰∫åÁ¥öÈ†êÈò≤Âà§ÂÆö)
        # ---------------------------------------------------------
        icd_codes = patient.get("icd_10") or actual_data.get("icd_10") or []
        if isinstance(icd_codes, str): icd_codes = [icd_codes]
        medical_history = str(patient.get("medical_history") or actual_data.get("medical_history") or "").lower()

        # ‰∫åÁ¥öÈ†êÈò≤ (Secondary Prevention) ÊéíÈô§Ê∏ÖÂñÆ
        secondary_icd_prefixes = ("i20", "i21", "i22", "i24", "i25", "i63", "i64", "i69", "z95.1", "z95.5")
        secondary_keywords = ["stroke", "myocardial infarction", "stent", "cabg", "‰∏≠È¢®", "ÂøÉËÇåÊ¢óÂ°û", "ÊîØÊû∂", "ÂÜ†ÂøÉÁóÖ", "ÂøÉËÇåÁº∫Ë°Ä"]
        
        is_secondary_prevention = False
        if any(str(code).lower().startswith(secondary_icd_prefixes) for code in icd_codes):
            is_secondary_prevention = True
        elif any(kw in medical_history for kw in secondary_keywords):
            is_secondary_prevention = True

        # ---------------------------------------------------------
        # üõ°Ô∏è [Èò≤Á∑ö 1] Áç®Á´ãÊñºÂäëÈáèÁöÑÁ°¨ÊÄßË¶èÂâá (Architecture Decoupling - Round 131)
        # ---------------------------------------------------------
        if ("aspirin" in drug_name or "bokey" in drug_name or "asa" in drug_name):
            # üö® ÁµïÂ∞çÊîîÊà™ÔºöÈ´òÈΩ°È´òÂäëÈáè (ÁÑ°Ë´ñ‰∏Ä‰∫åÁ¥öÈ†êÈò≤ÁöÜ‰∏çÈÅ©ÂêàÈï∑Êúü‰ΩøÁî®)
            # Ê≥®ÊÑèÔºöÈÄôË£°ÊúÉÂÖàÂòóË©¶ÂæûËó•ÂêçÈ†êÂà§ÂäëÈáèÔºåÂ¶ÇÊûúÊòØ >= 325mg Ââá HIGH_RISK
            if age_val >= 65 and re.search(r'(325|500)\s*mg', drug_name, re.I):
                return True, "HIGH_RISK", f"‚õî HARD RULE: È´òÈΩ°ËÄÖ ({age_val}Ê≠≤) Èï∑Êúü‰ΩøÁî®È´òÂäëÈáèÈòøÊñØÂåπÈùà (‚â•325mg) Âá∫Ë°ÄÈ¢®Èö™Ê•µÂ§ß„ÄÇÈô§ÊÄ•ÊÄßÊúüÂ§ñÊáâÈáçÊñ∞Ë©ï‰º∞ÂäëÈáèÊàñ‰ΩµÁî® PPI„ÄÇ"

            # ‚ö†Ô∏è Êô∫ËÉΩË≠¶Á§∫Ôºö‰∏ÄÁ¥öÈ†êÈò≤Êí§Ëó•Âª∫Ë≠∞ (‰∫åÁ¥öÈ†êÈò≤ËÄÖÊéíÈô§)
            if not is_secondary_prevention:
                if age_val >= 65:
                    return True, "PHARMACIST_REVIEW_REQUIRED", f"‚õî HARD RULE: AGS Beers Criteria 2023: {age_val}Ê≠≤Èï∑ËÄÖÊáâÈÅøÂÖçÈòøÊñØÂåπÈùà‰ΩúÁÇ∫„Äå‰∏ÄÁ¥öÈ†êÈò≤„Äç„ÄÇËã•ÁÑ°ÂøÉË°ÄÁÆ°ÁóÖÂè≤ÔºåÂª∫Ë≠∞ÂïüÂãïÊí§Ëó•Ë©ï‰º∞ (ÂèØÁõ¥Êé•ÂÅúËó•)„ÄÇ"
                elif age_val >= 60:
                    return True, "WARNING", f"‚ö†Ô∏è HARD RULE: USPSTF 2022: {age_val}Ê≠≤Èï∑ËÄÖ‰∏çÂª∫Ë≠∞Êñ∞ÂïüÂãïÈòøÊñØÂåπÈùà‰ΩúÁÇ∫‰∏ÄÁ¥öÈ†êÈò≤ÔºåÂá∫Ë°ÄÈ¢®Èö™È°ØËëóÂ§ßÊñºÊΩõÂú®Áç≤Áõä„ÄÇ"

        if age_val >= 65 and ("stilnox" in drug_name or "zolpidem" in drug_name):
             # ÊèêÈÜíÔºöÂç≥‰ΩøÂäëÈáèÊ≠£Á¢∫ÔºåZ-drugs Â∞çÈ´òÈΩ°ËÄÖ‰ªçÊòØÈ´òÈ¢®Èö™ (Beers Criteria)
             return True, "WARNING", f"‚ö†Ô∏è HARD RULE: AGS Beers Criteria 2023: Zolpidem (Age {age_val}) ÊúÉÈ°ØËëóÂ¢ûÂä†Ë∑åÂÄíËàáÈ™®ÊäòÈ¢®Èö™„ÄÇ‚ö†Ô∏èÂàáÂãøÁ™ÅÁÑ∂ÂÅúËó•ÔºåÊáâÁî±ÈÜ´Â∏´ÊåáÁ§∫ÈÄêÊº∏Ê∏õÈáè‰ª•ÂÖçÂºïÁôºÊàíÊñ∑‡•§"

        # ---------------------------------------------------------
        # üõ°Ô∏è [Èò≤Á∑ö 2] ‰æùË≥¥Êï∏ÂÄºÁöÑÂäëÈáèÊ™¢Êü• (Dosage Limits)
        # ---------------------------------------------------------
        raw_dose = str(drug.get("dose") or drug.get("dosage") or actual_data.get("dosage") or "0")
        
        # 1. ÂÖàÂü∑Ë°åÂ∏∏Ë¶èÊØ´ÂÖãËΩâÊèõ
        mg_vals, _ = normalize_dose_to_mg(raw_dose)

        # 2. [Fallback Extraction V1.7] Âê´„ÄåÈ°ÜÊï∏„ÄçÁ≤æÁ¢∫Ê¨äÈáçË®àÁÆó
        # Â¶ÇÊûúÂ∏∏Ë¶èËß£ÊûêÁµêÊûúÁÇ∫Á©∫ (‰æãÂ¶Ç "E.C." Êàñ "2Èå†")
        if not mg_vals:
            # ÂòóË©¶Âæû raw_dose ÊäìÂèñÊï∏Èáè (È†êË®≠ 1.0)
            pill_match = re.search(r'(\d+(?:\.\d+)?)\s*(È°Ü|Èå†|Á≤í|capsule|tablet)', str(raw_dose), re.I)
            pill_count = float(pill_match.group(1)) if pill_match else 1.0

            # ÂæûËó•ÂêçÊäìÂèñÂü∫Ê∫ñÊØ´ÂÖã
            fallback_match = re.search(r'(\d+)\s*mg', drug_name, flags=re.IGNORECASE)
            if fallback_match:
                base_mg = float(fallback_match.group(1))
                total_mg = base_mg * pill_count
                print(f"üîÑ [Dose Fallback V1.7] '{base_mg}mg' * {pill_count} pills = {total_mg}mg")
                mg_vals = [total_mg]

        for mg_val in mg_vals:
            if age_val >= 80 and ("glu" in drug_name or "metformin" in drug_name or "glucophage" in drug_name):
                if mg_val > 1000: return True, "PHARMACIST_REVIEW_REQUIRED", f"‚õî HARD RULE: Geriatric Max Dose Exceeded (Metformin {mg_val}mg > 1000mg)"
            elif age_val >= 65 and ("stilnox" in drug_name or "zolpidem" in drug_name):
                # [V1.7 Clinical Awareness] Âà§Êñ∑Èï∑ÊïàÂûã (CR/ER) ËàáÈÄüÊïàÂûã
                is_er = any(kw in drug_name.lower() for kw in ["cr", "er", "Èï∑Êïà", "ÊåÅÁ∫åÈáãÊîæ"])
                max_geriatric_dose = 6.25 if is_er else 5.0
                
                if mg_val > max_geriatric_dose: 
                    return True, "HIGH_RISK", f"‚õî HARD RULE: FDA ÂäëÈáèÈôêÂà∂Áï∞Â∏∏ÔºÅÈ´òÈΩ°ËÄÖ Zolpidem ({'Èï∑Êïà' if is_er else 'ÈÄüÊïà'}) ÊúÄÂ§ßÂäëÈáèÁÇ∫ {max_geriatric_dose}mg (Áï∂ÂâçËæ®Ë≠ò: {mg_val}mg)„ÄÇ‚ö†Ô∏èÊ≥®ÊÑèÔºöË´ãÁî±ÈÜ´Â∏´ÊåáÁ§∫ÈÄêÊº∏Ê∏õÈáèÔºåÂàáÂãøÁ™ÅÁÑ∂ÂÅúËó•„ÄÇ"
            elif "lipitor" in drug_name or "atorvastatin" in drug_name:
                if mg_val > 80: return True, "HIGH_RISK", f"‚õî HARD RULE: Atorvastatin Safety Limit ({mg_val}mg > 80mg)."
            elif "diovan" in drug_name or "valsartan" in drug_name:
                if mg_val > 320: return True, "HIGH_RISK", f"‚õî HARD RULE: Valsartan Safety Limit ({mg_val}mg > 320mg)."
            elif "panadol" in drug_name or "acetaminophen" in drug_name:
                if mg_val > 1000: 
                    return True, "HIGH_RISK", f"‚õî Acetaminophen Overdose: Single dose {mg_val}mg exceeds safe limit (1000mg)."
                # [V1.7 Precision Fix] ÁßªÈô§ return PASSÔºåÈÅøÂÖç‰∏≠Êñ∑Ëø¥ÂúàÂ∞éËá¥Ë∑≥ÈÅé‰∏ãÊñπÁöÑ Q1H Ê™¢Êü•
            elif "lisinopril" in drug_name and "potassium" in drug_name:
                return True, "WARNING", "‚ö†Ô∏è POTENTIAL INTERACTION: Lisinopril + Potassium supplement may cause hyperkalemia."
            
            # V12.0 Round 120.2: Separate Warfarin and Aspirin thresholds (CRITICAL FIX)
            # Bug: ‰πãÂâçÂ∞á Aspirin 100mg Ë™§Âà§ÁÇ∫ÈÅéÈáèÔºå‰ΩÜÈÄôÊòØÊ≠£Â∏∏ÂøÉË°ÄÁÆ°È†êÈò≤ÂäëÈáèÔºÅ
            elif "warfarin" in drug_name or "coumadin" in drug_name:
                # Warfarin: ËÄÅÂπ¥‰∫∫Á∂≠ÊåÅÂäëÈáèÈÄöÂ∏∏ 3-5mgÔºå>10mg Áñë‰ººÂ∞èÊï∏ÈªûÈåØË™§
                if mg_val > 10: 
                    return True, "HIGH_RISK", f"‚õî CRITICAL OVERDOSE RISK: Warfarin {mg_val}mg exceeds standard safety limits (typical elderly dose: 3-5mg). Check for decimal error."
            elif any(noac in drug_name for noac in ["rivaroxaban", "xarelto", "dabigatran", "pradaxa", "apixaban", "eliquis", "edoxaban"]):
                # NOACs: ÂäëÈáèÁï∞Â∏∏Ê™¢Ê∏¨ÔºàÈÄô‰∫õËó•Áâ©ÊúâÂõ∫ÂÆöÂäëÈáèÔºâ
                if mg_val > 30:  # Rivaroxaban ÊúÄÈ´ò 20mg, Apixaban ÊúÄÈ´ò 10mg
                    return True, "HIGH_RISK", f"‚õî CRITICAL: NOAC dose {mg_val}mg exceeds maximum approved dose."
            # ‚úÖ Aspirin 60+ logic consolidated above (Line 882)
            elif age_val >= 65 and ("plavix" in drug_name or "clopidogrel" in drug_name):
                # Clopidogrel: Ê®ôÊ∫ñÂäëÈáè 75mgÔºå> 75mg ÈúÄÁ¢∫Ë™ç
                if mg_val > 75:
                    return True, "WARNING", f"‚ö†Ô∏è Clopidogrel {mg_val}mg exceeds standard dose (75mg). Verify prescription."
            
            # [P0 Emergency Fix] General Extreme Dose Sentinel (Sent from normalize_dose_to_mg)
            if mg_val >= 9000:
                return True, "HIGH_RISK", f"‚õî CRITICAL: Extreme or multiplier dosage detected ({raw_dose}). Potential life-threatening overdose."

            # [P0 Emergency Fix] Bisoprolol (Concor) Geriatric Guardrail
            if age_val >= 65 and ("bisoprolol" in drug_name or "concor" in drug_name):
                if mg_val > 10: # Standard max for elderly is often 5-10mg
                    return True, "HIGH_RISK", f"‚õî HARD RULE: Geriatric Bisoprolol safety limit exceeded ({mg_val}mg > 10mg)."

        # [P0 Emergency Fix] Abnormality Keywords in Dose
        raw_dose_lower = str(raw_dose).lower()
        abnormal_keywords = ["normal", "ÂÄç", "excessive", "extreme", "abnormal", "ÂäëÈáèÁï∞Â∏∏", "Ë™øÊï¥"]
        if any(kw in raw_dose_lower for kw in abnormal_keywords) and ("x" in raw_dose_lower or re.search(r'\d+', raw_dose_lower)):
             return True, "HIGH_RISK", f"‚õî CRITICAL: Non-standard high-risk dosage detected: '{raw_dose}'"
        
        # [P0 Emergency Fix] Dangerous Frequency Detection (Q1H, ÊØèÂ∞èÊôÇ)
        usage_lower = str(actual_data.get("usage", "")).lower()
        if any(q in usage_lower for q in ["q1h", "q2h", "1Â∞èÊôÇ", "2Â∞èÊôÇ", "every 1 hour", "every hour"]):
            # Oral medications should never be Q1H
            return True, "HIGH_RISK", f"‚õî CRITICAL FREQUENCY: Dosing every 1-2 hours ({usage_lower}) is highly abnormal and dangerous for oral medication."
                
    except Exception as e:
        print(f"‚ö†Ô∏è Hard Rule Check Error: {e}")
    return False, None, None

def logical_consistency_check(extracted_data, safety_analysis=None, voice_context=""):
    """
    [Canonical] Logical Consistency Check (Neuro-Symbolic)
    Unifies logic from app.py and agent_engine.py.
    Returns: (is_passed, message, logs)
    """
    logs = []
    issues = []

    # 1. Parameter Normalization
    actual_data = extracted_data
    if "extracted_data" in extracted_data:
        actual_data = extracted_data["extracted_data"]
        if safety_analysis is None:
            safety_analysis = extracted_data.get("safety_analysis", {})

    if safety_analysis is None:
        safety_analysis = {}

    # 2. Schema Validation
    patient = actual_data.get("patient", {})
    drug = actual_data.get("drug", {})
    
    if not isinstance(patient, dict) or not isinstance(drug, dict):
        # Fallback for flat structure
        patient = {"age": actual_data.get("patient_age", 0)}
        drug = {"name": actual_data.get("drug_name", ""), "dose": actual_data.get("dosage", "")}

    # 3. Age & Hard Rules (Geriatric Guardrails)
    try:
        raw_age = patient.get("age") or 0
        age_val = int(raw_age)
        if age_val > 120: issues.append(f"Invalid Age: {age_val}")
        if 0 < age_val < 18: issues.append(f"Pediatric case ({age_val}) requires manual review")
    except:
        age_val = 0

    # Trigger Central Hard Rules
    is_triggered, rule_status, rule_reason = check_hard_safety_rules(actual_data, voice_context=voice_context)
    if is_triggered:
        # [P0 Fix] ÂåÖÂê´ÂØ©Ê†∏Ë¶ÅÊ±ÇËàáË≠¶ÂëäÔºåÈò≤Ê≠¢Ë¢´Áï∂ÊàêÊôÆÈÄö Note ÊîæË°å
        if rule_status in ["HIGH_RISK", "PHARMACIST_REVIEW_REQUIRED", "WARNING"]:
            issues.append(rule_reason)
        else:
            logs.append(f"Safety Note: {rule_reason}")

    # 4. [P0 Emergency Fix] Contradictory Reasoning Check (VLM Guard)
    reasoning_lower = str(safety_analysis.get("reasoning", "")).lower()
    negative_medical_terms = ["adjustment needed", "excessive", "high dose", "overdose", "abnormal", "Âç±Èö™", "ÈÅéÈ´ò", "ÈÅéÈáè", "‰∏çÂª∫Ë≠∞"]
    if any(k in reasoning_lower for k in negative_medical_terms):
        if safety_analysis.get("status") == "PASS":
            issues.append(f"‚õî SAFETY OVERRIDE: Reasoning indicated risk ('{reasoning_lower}') but status was PASS. Forcing review.")

    # üü¢ [FIX] Precedence: Critical Safety Rules > Unknown Drug
    # Check immediately after Hard Rules to prevent masking
    critical_issues = [i for i in issues if "CRITICAL" in i or "HARD RULE" in i or "HIGH_RISK" in i]
    if critical_issues:
            return False, f"‚õî CRITICAL SAFETY HALT: {'; '.join(critical_issues)}", logs

    # 4. Drug Knowledge Base Presence (Anti-Hallucination)
    drug_name = drug.get("name") or actual_data.get("drug_name") or ""
    if drug_name:
        is_known = offline_db_lookup(drug_name)
        if not is_known:
            if "unknown" in str(drug_name).lower():
                return True, "‚ö†Ô∏è UNKNOWN_DRUG detected. Manual Review Required.", logs
            else:
                issues.append(f"Drug not in knowledge base: {drug_name}")

    # 5. Reasoning Consistency (VLM Audit)
    status = safety_analysis.get("status", "")
    reasoning = safety_analysis.get("reasoning", "")
    if status == "HIGH_RISK" and drug_name and drug_name.lower() not in str(reasoning).lower():
        issues.append("Safety Reasoning does not mention the flagged drug name.")

    if issues:
        # Prevent infinite retry for unknown drugs if flagged
        if any("not in knowledge base" in issue for issue in issues):
            return True, f"‚ö†Ô∏è UNKNOWN_DRUG detected: {drug_name}. Manual Review Required.", logs
        return False, f"Logic Consistency Failed: {'; '.join(issues)}", logs

    return True, "Logic Consistent", logs

def offline_db_lookup(drug_name):
    """
    Simulates checking against a trusted offline database.
    Returns True if drug exists in approved list.
    """
    try:
        # [V8 Fix] Robust Cleaning before Lookup
        def clean_name_internal(name):
            name = re.sub(r'\s*\d+\.?\d*\s*(mg|g|mcg|ug|ml|ÊØ´ÂÖã|ÂÖ¨ÂÖã)\b', '', str(name), flags=re.IGNORECASE)
            name = re.sub(r'\s*\([^)]*\)', '', name).strip().lower()
            return name
        
        # [V11.1] Critical Fix: Check Safe Substrings FIRST (Before cleaning strips essential chars)
        # Uses global SAFE_SUBSTRINGS defined at module level
        
        # Case-insensitive check on raw name first
        if any(safe in str(drug_name).lower() for safe in SAFE_SUBSTRINGS):
            return True

        target = clean_name_internal(drug_name)
        
        db = DRUG_DATABASE
        candidates = []
        for category in db.values():
            for item in category:
                if target in [item['name_en'].lower(), item['name_zh'].lower(), item['generic'].lower()]:
                    return True
                candidates.append(item['name_en'].lower())
                candidates.append(item['generic'].lower())

        if target in DRUG_ALIASES:
            return True
        candidates.extend(DRUG_ALIASES.keys())
        
        import difflib
        matches = difflib.get_close_matches(target, candidates, n=1, cutoff=0.7)
        if matches:
            return True

        if any(safe in target for safe in SAFE_SUBSTRINGS):
            return True

        return False
    except ImportError:
        SAFE_LIST = ["warfarin", "aspirin", "furosemide", "metformin", "amlodipine", 
                        "plavix", "stilnox", "lipitor", "crestor", "bisoprolol",
                        "bokey", "licodin", "diovan", "xanax", "valium", "panadol", "acetaminophen"]
        return any(d in drug_name.lower() for d in SAFE_LIST)

def safety_critic_tool(json_output):
    """
    The 'Callable Tool' that acts as the Critic (Rule-Based).
    """
    import re
    try:
        data = json_output if isinstance(json_output, dict) else json.loads(json_output)
    
        extracted = data.get("extracted_data", {})
        raw_name = extracted.get("drug", {}).get("name", "")
        if not raw_name: raw_name = str(extracted.get("drug", ""))
    
        # [V8 Fix] Use broad cleaning (mg, g, mcg, ug, ml, tablets, etc.)
        clean_name = re.sub(r'\s*\d+\.?\d*\s*(mg|g|mcg|ug|ml|ÊØ´ÂÖã|ÂÖ¨ÂÖã|È°Ü|tablets?)\b', '', raw_name, flags=re.IGNORECASE)
        clean_name = re.sub(r'\s*\([^)]*\)', '', clean_name).strip()
    
        # Rule 1: Conflict Check
        if "Warfarin" in clean_name and "Aspirin" in clean_name:
                return False, "CRITICAL INTERACTION: Warfarin and Aspirin detected together. Immediate Verification Needed."

        # Rule 2: Hallucination Check
        if clean_name and not("unknown" in clean_name.lower()):
            if not offline_db_lookup(clean_name):
                if not offline_db_lookup(raw_name):
                    return False, f"Drug '{raw_name}' (Cleaned: '{clean_name}') not found in approved local database (Possible Hallucination)."

        # Rule 3: Dosage Sanity Check
        dose = extracted.get("drug", {}).get("dose", "")
        if dose and any(x in dose for x in ["2000mg", "7000mg"]): # 2000mg is allowed for Metformin, but suspicious if not checked
            pass 

        return True, "Logic Sound."
    
    except Exception as e:
        return False, f"Critic Tool Error: {str(e)}"

def check_is_prescription(response_text):
    """
    üõ°Ô∏è [Round 126] Enhanced OOD Detection - Reject non-medical images
    Èò≤Ê≠¢ ETF„ÄÅÈ¢®ÊôØÁÖß„ÄÅË≤ìÂí™ÁÖßË¢´Âº∑Ë°åËß£ÈáãÊàêËó•Áâ©
    """
    # Ê†∏ÂøÉÈÜ´ÁôÇÈóúÈçµÂ≠óÔºàÂøÖÈ†àÂåÖÂê´ÈÄô‰∫õÊâçÁÆóÈÜ´ÁôÇÂÖßÂÆπÔºâ
    CORE_MEDICAL_KEYWORDS = [
        "Ëó•", "drug", "medicine", "pill", "tablet", "capsule", 
        "mg", "mcg", "g", "ml",  # ÂäëÈáèÂñÆ‰Ωç
        "ÊúçÁî®", "Êó©Êôö", "È£ØÂæå", "Áù°Ââç", "use", "take", "daily",
        "indication", "side effect", "warning", "ÂâØ‰ΩúÁî®", "ÈÅ©ÊáâÁóá",
        "pharmacy", "hospital", "Ë®∫ÊâÄ", "ÈÜ´Èô¢", "prescription",
        "patient", "dose", "dosage", "medication", "Ê≤ªÁôÇ"
    ]
    
    # ÊéíÈô§ÈóúÈçµÂ≠óÔºàÂ¶ÇÊûúÂåÖÂê´ÈÄô‰∫õÔºåÂ§ßÊ¶ÇÁéá‰∏çÊòØËó•ÂñÆÔºâ
    EXCLUDE_KEYWORDS = [
        "etf", "exchange traded fund", "stock", "ÊäïË≥á", "Âü∫Èáë",
        "0050", "2330", "ËÇ°Á•®", "trading", "portfolio"
    ]
    
    response_lower = str(response_text).lower()
    
    # Ê™¢Êü•ÊéíÈô§ÈóúÈçµÂ≠ó
    for exclude_kw in EXCLUDE_KEYWORDS:
        if exclude_kw in response_lower:
            return False
    
    # Ë®àÁÆóÈÜ´ÁôÇÈóúÈçµÂ≠óÂëΩ‰∏≠Êï∏
    keyword_count = sum(1 for kw in CORE_MEDICAL_KEYWORDS if kw.lower() in response_lower)
    
    # ÈñÄÊ™ªÔºöËá≥Â∞ëË¶ÅÂëΩ‰∏≠ 2 ÂÄãÈÜ´ÁôÇÈóúÈçµÂ≠óÊâçÁÆóÊòØËôïÊñπÁÆã (ÂéüÁÇ∫ 4ÔºåÈáùÂ∞çÁü≠ÂõûË¶ÜÈÄ≤Ë°åÂÑ™Âåñ)
    # (‰æãÂ¶ÇÂè™Êúâ "Aspirin 100mg" ‰πüÊáâË©≤ÈÅé)
    if keyword_count >= 2:
        return True
    
    return False
