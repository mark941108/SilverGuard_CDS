
import os
import re
import json
import logging
import ast
import numpy as np
import cv2
from PIL import Image
import torch
from pathlib import Path

# å…¨å±€è®Šæ•¸ä½”ä½ç¬¦ (å°‡ç”± app.py æ³¨å…¥)
DRUG_ALIASES = {}
DRUG_DATABASE = {}
_SYNTHETIC_DATA_GEN_SOURCE = {}
BLUR_THRESHOLD = 25.0  # [Red Team Fix] Lowered for handheld demo stability

# [V11.0] Layer 3: Safe Substrings (Whitelist for trusted meds)
# Fixes "Aspirin E.C." or "Panadol Extra" being flagged as Unknown
SAFE_SUBSTRINGS = ["aspirin", "bokey", "panadol", "acetaminophen", "warfarin", "coumadin", 
                   "metformin", "glucophage", "stilnox", "zolpidem", "plavix", "clopidogrel",
                   "diovan", "valsartan", "norvasc", "amlodipine", "concor", "bisoprolol",
                   "lasix", "furosemide", "lipitor", "atorvastatin", "crestor", "rosuvastatin",
                   "xanax", "alprazolam", "valium", "diazepam", "rivaroxaban", "xarelto"]

def get_environment():
    """
    ğŸŒ çµ±ä¸€ç’°å¢ƒåˆ¤æ–· (Environment Unification)
    ç¢ºä¿å…¨ç³»çµ±çš„è·¯å¾‘èˆ‡è¡Œç‚ºä¸€è‡´
    """
    if os.path.exists("/kaggle/working"):
        return "KAGGLE"
    elif os.getenv("SPACE_ID"):
        return "HF_SPACE"
    else:
        return "LOCAL"

def extract_generic_from_context(full_data, drug_name_with_parentheses=None):
    """
    ğŸ§  Enhanced Context-Aware Drug Extraction (Round 120.1 Hardening)
    å¾å¤šå€‹ä¾†æºæå–è—¥ç‰©å­¸åï¼Œä½œç‚ºäºŒæ¬¡é©—è­‰ä¾†æº
    
    ç­–ç•¥å„ªå…ˆé †åºï¼š
    1. å¾è—¥ç‰©åç¨±çš„æ‹¬è™Ÿå…§æå–ï¼ˆæœ€å¯é ï¼‰
    2. å¾ safety_analysis.reasoning æå–
    3. å¾å®Œæ•´ VLM åŸå§‹è¼¸å‡ºæ–‡å­—æå–ï¼ˆæœ€å¼·å¥ï¼‰
    
    Args:
        full_data: å®Œæ•´çš„ VLM è¼¸å‡ºå­—å…¸
        drug_name_with_parentheses: è—¥ç‰©åç¨±ï¼ˆå¯èƒ½åŒ…å«æ‹¬è™Ÿå­¸åï¼‰
    
    Returns:
        matched_generic: åœ¨è³‡æ–™åº«ä¸­æ‰¾åˆ°çš„å­¸åï¼Œè‹¥ç„¡å‰‡è¿”å› None
    """
    import re
    
    try:
        # Strategy 1: Extract from parentheses in drug name
        # Example: "Dilatrend 25mg (Carvedilol)" â†’ "Carvedilol"
        if drug_name_with_parentheses:
            paren_match = re.search(r'\(([^)]+)\)', drug_name_with_parentheses)
            if paren_match:
                potential_generic = paren_match.group(1).strip().lower()
                # Verify against database
                if DRUG_DATABASE:
                    for cat, items in DRUG_DATABASE.items():
                        for item in items:
                            if potential_generic == str(item.get("generic", "")).lower():
                                print(f"ğŸ” [Parentheses Extraction] Found '{potential_generic}' â†’ {item['name_en']}")
                                return item["name_en"]
        
        # Strategy 2: Extract from safety_analysis.reasoning (original logic)
        reasoning = ""
        if isinstance(full_data, dict):
            safety = full_data.get("safety_analysis", {})
            if isinstance(safety, dict):
                reasoning = str(safety.get("reasoning", "")).lower()
        
        # Strategy 3: Fallback to full VLM output text (most robust)
        # VLM might output text like "Drug Dilatrend (Carvedilol)" outside JSON
        full_text = ""
        if isinstance(full_data, dict):
            # Try to get any text-based field that might contain drug info
            full_text = str(full_data).lower()
        
        # Combine all text sources
        combined_text = reasoning + " " + full_text
        
        if not combined_text.strip() or not DRUG_DATABASE:
            return None
        
        # Build candidate list
        generic_candidates = []
        for cat, items in DRUG_DATABASE.items():
            for item in items:
                generic = str(item.get("generic", "")).lower().strip()
                brand = str(item.get("name_en", "")).lower().strip()
                if generic and len(generic) > 3:
                    generic_candidates.append((generic, brand, item["name_en"]))
        
        # Search for generics in combined text
        for generic, brand_lower, brand_display in generic_candidates:
            # Precise word boundary match
            pattern = r'\b' + re.escape(generic) + r'\b'
            if re.search(pattern, combined_text, re.IGNORECASE):
                print(f"ğŸ§  [Context-Aware RAG] Extracted '{generic}' (â†’ {brand_display}) from context")
                return brand_display
        
        return None
        
    except Exception as e:
        print(f"âš ï¸ [Context Extraction Error] {e}")
        return None


def bidirectional_rag_filter(drug_name):
    """
    ğŸ” Bidirectional RAG Verification (Ghost Drug Filter)
    [Fixed] å¢å¼·å° OCR é›œè¨Šçš„æŠ—æ€§ï¼Œé™ä½èª¤æ®ºç‡
    """
    # ğŸ›¡ï¸ [Round 120.4] Debug logging for Hydroxyzine bug
    DEBUG_VERBOSE = False  # Debugging complete

    
    if not drug_name or str(drug_name).lower() == "unknown":
        return True # é è¨­æ”¾è¡Œ
        
    if not DRUG_DATABASE:
        if DEBUG_VERBOSE:
            print(f"âš ï¸ [RAG Filter] DRUG_DATABASE is empty! Allowing '{drug_name}'")
        return True # ç„¡è³‡æ–™åº«å¯æ¯”å°ï¼Œç›´æ¥æ”¾è¡Œ
    else:
        if DEBUG_VERBOSE:
            db_size = sum(len(items) for items in DRUG_DATABASE.values())
            print(f"ğŸ” [RAG Filter] DB loaded ({db_size} drugs). Testing: '{drug_name}'")

    import difflib
    import re
    
    q_raw = str(drug_name).lower().strip()
    
    # [V11.2 Round 103] Proactive Whitelist check
    # Check global SAFE_SUBSTRINGS first to avoid RAG false positives for trusted meds
    if any(safe in q_raw for safe in SAFE_SUBSTRINGS):
        return True

    # ğŸ§¹ 1. æ¸…ç†å¸¸è¦‹çš„ OCR é›œè¨Šèˆ‡åŠ‘é‡å–®ä½ (ä¾‹å¦‚: "è„ˆå„ªéŒ  5mg" -> "è„ˆå„ª")
    q_clean = re.sub(r'\s*\d+\.?\d*\s*(mg|g|mcg|ug|ml|æ¯«å…‹|å…¬å…‹|éŒ |é¡†|ç²’|capsule|tablet)s?\b', '', q_raw).strip()
    q_clean = re.sub(r'[\(\)\[\]ï¼ˆï¼‰]', '', q_clean).strip()

    if q_clean in DRUG_ALIASES or q_raw in DRUG_ALIASES:
        return True
        
    ARTIFACTS = ["step", "extraction", "think", "reason", "protocol", "json", "result", "analysis"]
    if any(art in q_clean for art in ARTIFACTS):
        return False # é€™æ˜¯ AI çš„æ€è€ƒé›œè¨Šï¼Œæ””æˆª
        
    candidates = []
    for cat, items in DRUG_DATABASE.items():
        for item in items:
            candidates.extend([item['name_en'].lower(), item['name_zh'].lower(), item['generic'].lower()])
    
    # ğŸŸ¢ 2. å­å­—ä¸²æ¯”å° (Substring Match) - åªè¦æœ‰åŒ…å«å°±çµ¦é
    for c in candidates:
        if c and (c in q_clean or q_clean in c):
            return True
            
    # ğŸŸ¢ 3. æ”¾å¯¬æ¨¡ç³Šæ¯”å°é–€æª» (0.85 -> 0.60)
    matches = difflib.get_close_matches(q_clean, candidates, n=1, cutoff=0.60)
    if len(matches) > 0:
        return True
        
    # ğŸš¨ RAG Shield will be triggered (logging handled by neutralize_hallucinations)
    return False


def neutralize_hallucinations(data, context="", full_data=None):
    """
    â˜¢ï¸ æ ¸ç´šé˜²å¹»è¦ºè­·ç›¾ V3.2ï¼šå¼•å…¥é›™å‘ RAG é©—è­‰ + Context-Aware æ™ºèƒ½é™ç´š
    [V3.1] æ”¯æ´ Context æ„ŸçŸ¥ï¼Œé¿å…èª¤æ®ºæ‚£è€…å§“å
    [V3.2 Round 120] å¾ reasoning æå–å­¸åé€²è¡ŒäºŒæ¬¡é©—è­‰ï¼Œæ¸›å°‘èª¤å ±
    
    Args:
        data: è¦è™•ç†çš„è³‡æ–™ï¼ˆå­—å…¸/åˆ—è¡¨/åŸºæœ¬å‹åˆ¥ï¼‰
        context: ç•¶å‰è™•ç†çš„ä¸Šä¸‹æ–‡ï¼ˆ"patient_scope" ç­‰ï¼‰
        full_data: å®Œæ•´çš„ VLM è¼¸å‡ºï¼ˆç”¨æ–¼æå– reasoningï¼‰
    """
    # ğŸ›¡ï¸ [POC / DEMO ONLY] éš±ç§è­·ç›¾ (Privacy Shield) æ¦‚å¿µé©—è­‰
    # ç«¶è³½å±•ç¤ºå°ˆç”¨ï¼šæ­¤è™•ä½¿ç”¨éœæ…‹é™£åˆ—æ””æˆªç‰¹å®šçš„æ¸¬è©¦è³‡æ–™å€‹è³‡ä»¥é˜²æ­¢å¤–æ´©ã€‚
    # æ–¼çœŸå¯¦ç”¢å“ç’°å¢ƒ (Production) ä¸­ï¼Œæ­¤æ¨¡çµ„å°‡ä¸²æ¥æ­£è¦çš„ Medical NER (å‘½åå¯¦é«”è¾¨è­˜) æ¨¡å‹ï¼Œ
    # è‡ªå‹•è­˜åˆ¥ä¸¦é®è”½æ‰€æœ‰æœªçŸ¥çš„ç—…æ‚£å§“å (Name) èˆ‡å¹´é½¡ (Age)ã€‚
    BANNED_NAMES = ["åŠ‰æ·‘èŠ¬", "ç‹å¤§æ˜", "é™³å°æ˜"]
    BANNED_AGES = ["79", "83", "88"]
    
    if isinstance(data, dict):
        new_data = {}
        for k, v in data.items():
            val_str = str(v).strip()
            
            # å…ˆè™•ç†éè¿´
            if isinstance(v, (dict, list)):
                # ğŸŸ¢ [Fix] å¦‚æœç•¶å‰ key æ˜¯ patientï¼Œæ¨™è¨˜ context ç‚º "patient_scope"
                new_context = "patient_scope" if k == "patient" else context
                # ğŸ§  [V3.2] å‘ä¸‹å‚³é full_data ä»¥æ”¯æ´ context-aware æå–
                new_data[k] = neutralize_hallucinations(v, context=new_context, full_data=full_data or data)
                continue

            # 1. éš±ç§ä¸­å’Œ (å§“å/å¹´é½¡)
            if k in ["name", "detected_name"] and val_str in BANNED_NAMES:
                 print(f"ğŸ›¡ï¸ [Shield] Neutralized Banned Name: {v}")
                 new_data[k] = "Unknown"
            elif k == "age" and val_str in BANNED_AGES:
                 print(f"ğŸ›¡ï¸ [Shield] Neutralized Banned Age: {v}")
                 new_data[k] = "Unknown"
            
            # 2. é›™å‘ RAG é©—è­‰ (å¹½éˆè—¥å“éæ¿¾) + æ™ºèƒ½é™ç´š
            elif k in ["name", "drug_name", "drug", "zh", "generic"]:
                # ğŸŸ¢ [Fix] å¦‚æœèº«è™• patient_scopeï¼Œè·³é RAG æª¢æŸ¥
                if context == "patient_scope":
                    new_data[k] = v
                elif not bidirectional_rag_filter(val_str):
                    # ğŸ§  [V3.2] æ™ºèƒ½é™ç´šï¼šå˜—è©¦å¤šé‡ç­–ç•¥æå–å­¸å
                    contextual_match = None
                    if full_data:
                        # Pass the drug name itself for parentheses extraction
                        contextual_match = extract_generic_from_context(
                            full_data, 
                            drug_name_with_parentheses=val_str
                        )
                    
                        # Case A: åœ¨ context ä¸­æ‰¾åˆ°å·²çŸ¥è—¥ç‰©å­¸å
                        print(f"ğŸ” [Smart Degradation] '{val_str}' â†’ Likely '{contextual_match}' (via context)")
                        new_data[k] = f"âš ï¸æ¨æ¸¬ç‚º: {contextual_match} (æœªé©—è­‰)"
                    else:
                        # Case B: çœŸæ­£çš„æœªçŸ¥è—¥ç‰© - è»Ÿæ€§æ¨™è¨˜ä¿ç•™
                        print(f"âš ï¸ [RAG] æœªçŸ¥è—¥ç‰©ä¿ç•™: {val_str}")
                        new_data[k] = f"{v} (âš ï¸è³‡æ–™åº«æœªæ”¶éŒ„)"
                else:
                    new_data[k] = v
            else:
                new_data[k] = v
        return new_data
    
    elif isinstance(data, list):
        return [neutralize_hallucinations(item, context, full_data=full_data) for item in data]
    
    return data

def calculate_confidence(model, outputs, processor):
    """
    Entropy-aware Confidence Calculation
    """
    try:
        transition_scores = model.compute_transition_scores(
            outputs.sequences, outputs.scores, normalize_logits=True
        )
        probs = torch.exp(transition_scores)
        min_prob = probs.min().item()
        mean_prob = probs.mean().item()
        alpha = 0.75
        return (mean_prob * alpha) + (min_prob * (1 - alpha))
    except:
        return 0.0

def get_confidence_status(confidence, predicted_status="UNKNOWN", custom_threshold=None):
    """
    Dynamic Thresholding
    """
    if custom_threshold is not None:
        threshold = custom_threshold
    else:
        # [V1.0 Impact] Dual-Threshold System: Recall for Risk (0.50), Precision for Safety (0.70)
        threshold = 0.50 if predicted_status in ["HIGH_RISK", "PHARMACIST_REVIEW_REQUIRED"] else 0.70
        
    if confidence >= threshold:
        return "HIGH_CONFIDENCE", f"âœ… Conf: {confidence:.1%} (Th: {threshold})"
    return "LOW_CONFIDENCE", f"âš ï¸ Unsure ({confidence:.1%}) -> ESCALATE"

# å…¨å±€ OCR å¼•æ“ (æ‡¶åŠ è¼‰)
OCR_READER = None 

_UNIFIED_RAG_INSTANCE = None

def resolve_drug_name_zh(raw_name):
    """
    å°‡è‹±æ–‡è—¥åå°ç…§è³‡æ–™åº«è½‰æ›ç‚ºä¸­æ–‡è—¥å (Localization Support)
    """
    if not raw_name or raw_name == "æœªçŸ¥è—¥ç‰©":
        return raw_name
    
    # æ¸…ç†åç¨± (ç§»é™¤åŠ‘é‡èˆ‡æ‹¬è™Ÿé›œè¨Šï¼Œä¾‹å¦‚ "Norvasc 5mg" -> "norvasc")
    clean_name = re.sub(r'\s*\d+\.?\d*\s*(mg|g|mcg|ug|ml|æ¯«å…‹|å…¬å…‹)\b', '', str(raw_name), flags=re.IGNORECASE)
    clean_name = re.sub(r'\s*\([^)]*\)', '', clean_name).strip().lower()
    
    # 1. ç›´æ¥å‘½ä¸­åˆ¥å
    target = DRUG_ALIASES.get(clean_name, clean_name)
    
    # 2. éæ­·è³‡æ–™åº«é€²è¡ŒåŒ¹é…
    if DRUG_DATABASE:
        best_match = None
        best_score = 0
        
        for category in DRUG_DATABASE.values():
            for item in category:
                # å®Œæ•´åŒ¹é…è‹±æ–‡åæˆ–é€šç”¨å
                if target in [item['name_en'].lower(), item['generic'].lower()]:
                    return item['name_zh']
                
                # æ¨¡ç³ŠåŒ¹é… (é‡å° OCR èª¤å‚³ï¼Œå¦‚ Aspirinh -> Aspirin)
                # ä½¿ç”¨ç°¡å–®çš„å­—å…ƒé‡åˆåº¦æˆ– difflib
                from difflib import SequenceMatcher
                for candidate in [item['name_en'].lower(), item['generic'].lower()]:
                    score = SequenceMatcher(None, target, candidate).ratio()
                    if score > 0.85 and score > best_score:
                        best_score = score
                        best_match = item['name_zh']

                # é—œéµå­—åŒ…å«åŒ¹é… (ä¾‹å¦‚ VLM åå‡º "Glucophage Tablets")
                # [Integrity Fix] æé«˜å­å­—ä¸²æ¯”å°åš´æ ¼åº¦ï¼Œé˜²æ­¢ short-string èª¤å ± (ä¾‹å¦‚ "the" -> "Metformin")
                if clean_name and len(clean_name) >= 5 and (clean_name in item['name_en'].lower() or item['name_en'].lower() in clean_name):
                    return item['name_zh']
        
        # å¦‚æœæ¨¡ç³ŠåŒ¹é…åˆ†æ•¸å¤ é«˜ï¼Œå‰‡æ¡ç”¨
        if best_match and best_score > 0.85:
            print(f"ğŸ›¡ï¸ [Fuzzy Fix] {raw_name} -> {best_match} (Score: {best_score:.2f})")
            return best_match
                
    return raw_name # æ‰¾ä¸åˆ°å‰‡å›å‚³åŸå§‹åç¨± (è‡³å°‘æœ‰åŸå§‹è³‡è¨Š)

def get_rag_engine():
    """Singleton for the Unified RAG Engine."""
    global _UNIFIED_RAG_INSTANCE
    if _UNIFIED_RAG_INSTANCE is None:
        _UNIFIED_RAG_INSTANCE = UnifiedRAGEngine()
    return _UNIFIED_RAG_INSTANCE

class UnifiedRAGEngine:
    """
    ğŸ§  Unified RAG Engine (V10.0 Integrated)
    Combines: Vector Search (High Precision) + Fuzzy Match (Robust Fallback)
    """
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(UnifiedRAGEngine, cls).__new__(cls)
            cls._instance.initialized = False
        return cls._instance

    def __init__(self):
        if self.initialized: return
        self.vector_engine = None
        self.rag_available = False

        self.initialized = True
        self.index = None
        self.drug_database = {}
        self.fuzzy_cache = {"candidates": [], "lookup": {}}
        self._needs_fuzzy_rebuild = True
        self._setup_vector_if_possible()

    def inject_data(self, db):
        """Inject drug database and trigger rebuild of cache."""
        # ğŸŸ¢ [Fix] Handle empty DB gracefully
        if not db: 
            self.drug_database = {}
            self._needs_fuzzy_rebuild = True  # Force rebuild to clear cache
            print("âš ï¸ [RAG] Empty database injected. Cache cleared.")
            return

        self.drug_database = db
        # Also sync global DRUG_DATABASE for other components
        global DRUG_DATABASE
        DRUG_DATABASE = db
        self._needs_fuzzy_rebuild = True
        
        # âœ… [Round 121 Fix] è¨ˆç®—å¯¦éš›è—¥ç‰©ç¸½æ•¸
        total_drugs = sum(len(items) for items in db.values() if isinstance(items, list))
        print(f"ğŸ“Š [RAG] Data injected: {len(db)} categories, {total_drugs} total drugs")

    def _rebuild_fuzzy_cache(self):
        """Build candidates and lookup for fuzzy matching."""
        candidates = []
        lookup = {}
        db = self.drug_database or DRUG_DATABASE
        
        # âœ… [Round 122 Fix] æ˜ç¢ºè™•ç†å­—å…¸çµæ§‹ï¼Œç¢ºä¿éæ­·æ‰€æœ‰è—¥ç‰©
        all_items = []
        if isinstance(db, dict):
            # éæ­·æ‰€æœ‰åˆ†é¡çš„è—¥ç‰©åˆ—è¡¨
            for category_items in db.values():
                if isinstance(category_items, list):
                    all_items.extend(category_items)
        elif isinstance(db, list):
            all_items = db
        else:
            print(f"âš ï¸ [RAG] Unexpected database type: {type(db)}")
            all_items = []
        
        # å»ºç«‹æœå°‹ç´¢å¼•
        for item in all_items:
            en = item.get('name_en', '').lower()
            gen = item.get('generic', '').lower()
            zh = item.get('name_zh', '').lower()
            if en: 
                candidates.append(en)
                lookup[en] = item
            if gen: 
                candidates.append(gen)
                lookup[gen] = item
            if zh:
                candidates.append(zh)
                lookup[zh] = item
        
        # âœ… [Round 121 Fix] æ·»åŠ è©³ç´°è¼‰å…¥æ—¥èªŒ
        total_drugs = len(all_items)
        total_categories = len(db) if isinstance(db, dict) else 0
        print(f"ğŸ“Š [RAG Cache] Rebuilt: {total_categories} categories, {total_drugs} drugs, {len(candidates)} searchable terms")
        
        self.fuzzy_cache = {"candidates": candidates, "lookup": lookup}
        self._needs_fuzzy_rebuild = False

    def _setup_vector_if_possible(self):
        try:
            import faiss
            from sentence_transformers import SentenceTransformer
            # Note: We use a lightweight model for vector RAG
            self.rag_available = True
            print("ğŸš€ [RAG] Vector Search enabled (FAISS).")
        except ImportError:
            self.rag_available = False
            print("âš ï¸ [RAG] Vector dependencies missing. Falling back to Fuzzy logic.")


    def query(self, q, k=1):
        """Query the knowledge base."""
        # 1. Check for need to rebuild cache
        if self._needs_fuzzy_rebuild:
            self._rebuild_fuzzy_cache()

        # Check if Vector RAG is available and index is loaded
        if self.rag_available and self.index:
             # Strategy 1: Vector Search (Conceptual / Lazy Load)
             # [Future Implementation]
             pass

        # Strategy 2: Fuzzy Match (Canonical Fallback)
        import difflib
        q_lower = str(q).lower()
        candidates = self.fuzzy_cache["candidates"]
        lookup = self.fuzzy_cache["lookup"]
        
        if not candidates:
            return None, 1.0

        matches = difflib.get_close_matches(q_lower, candidates, n=1, cutoff=0.85) # âœ… æé«˜åˆ° 0.85 (Safety First)
        if matches:
            match_key = matches[0]
            info = lookup.get(match_key, {})
            k_result = (f"Official Name: {info.get('name_en')}\n"
                        f"Generic: {info.get('generic')}\n"
                        f"Indication: {info.get('indication')}\n"
                        f"Standard Dose: {info.get('dose')}\n"
                        f"Warning: {info.get('warning')}\n"
                        f"Usage: {info.get('default_usage')}")
            dist = 1.0 - difflib.SequenceMatcher(None, q_lower, match_key).ratio()
            return k_result, dist
        
        return None, 1.0

    def get_drug_data(self, q):
        """Returns the raw drug dictionary for compatibility with app.py."""
        if self._needs_fuzzy_rebuild:
            self._rebuild_fuzzy_cache()

        import difflib
        q_lower = str(q).lower()
        candidates = self.fuzzy_cache["candidates"]
        lookup = self.fuzzy_cache["lookup"]
        
        if not candidates:
            return {"found": False, "name_en": q, "warning": "âš ï¸ Database Empty.", "risk": "UNKNOWN_DRUG"}

        # Exact check
        if q_lower in lookup:
            return {**lookup[q_lower], "found": True, "match_type": "EXACT"}

        # Substring check (V15 Feature: æå‡æ¯”å°å¯¬å®¹åº¦)
        # Fixes: "é˜¿æ–¯åŒ¹éˆ" vs "ä¼¯åŸº/é˜¿æ–¯åŒ¹éˆ"
        for candidate, info in lookup.items():
            if len(q_lower) >= 2 and (q_lower in candidate or candidate in q_lower):
                return {**info, "found": True, "match_type": "SUBSTRING"}

        # Fuzzy check
        matches = difflib.get_close_matches(q_lower, candidates, n=1, cutoff=0.8)
        if matches:
            match_key = matches[0]
            info = lookup.get(match_key, {})
            sim = difflib.SequenceMatcher(None, q_lower, match_key).ratio()
            return {**info, "found": True, "match_type": f"FUZZY ({sim:.2f})"}
            
        return {
            "found": False, 
            "class": "Unknown", 
            "name_en": q,
            "warning": "âš ï¸ UNKNOWN DRUG DETECTED. SYSTEM CANNOT VERIFY SAFETY.",
            "risk": "UNKNOWN_DRUG"
        }

def retrieve_drug_info(drug_name):
    """
    [Unification Wrapper]
    Enables app.py and agent_engine.py to use the singleton RAG engine 
    with a consistent dictionary output.
    """
    return get_rag_engine().get_drug_data(drug_name)

def check_image_quality(image_path):
    """
    ğŸ” Input Validation Gate (Blur Detection + Size Check)
    Returns: (is_valid, quality_score, message)
    """
    try:
        # Handle numpy array (from Gradio) or file path
        if isinstance(image_path, str):
            img = cv2.imread(image_path)
        elif isinstance(image_path, Path):
            img = cv2.imread(str(image_path))
        elif isinstance(image_path, np.ndarray):
            img = image_path
        else:
            return False, 0.0, "ç„¡æ•ˆçš„å½±åƒæ ¼å¼"

        if img is None:
            return False, 0.0, "ç„¡æ³•è®€å–å½±åƒæª”æ¡ˆ"
        
        # 1. Blur Detection (Laplacian Variance)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # 2. Size Check
        h, w = img.shape[:2]
        if w < 200 or h < 200:
            return False, laplacian_var, f"å½±åƒå°ºå¯¸éå° ({w}x{h})"
        
        # 3. Threshold Check (BLUR_THRESHOLD defined globally in utils)
        # Using a safer local default if global is missing
        threshold = globals().get('BLUR_THRESHOLD', 25.0) 
        
        if laplacian_var < threshold:
            return False, laplacian_var, f"å½±åƒæ¨¡ç³Š (åˆ†æ•¸: {laplacian_var:.1f} < {threshold})"
        
        return True, laplacian_var, "å½±åƒå“è³ªè‰¯å¥½"
        
    except Exception as e:
        print(f"âš ï¸ Image Check Error: {e}")
        return True, 100.0, "å“è³ªæª¢æŸ¥è·³é (Error)" # Fail open for demo stability

def clean_text_for_tts(text, lang='zh-tw'):
    """
    ğŸ”Š [V15.0] Robust TTS Text Cleaner (Medical Jargon to Elder-Friendly Language)
    1. Removes JSON artifacts and special characters.
    2. Translates medical English abbreviations to target language.
    3. Filters out internal reasoning artifacts (Step 1, Reasoning, etc.).
    4. Normalizes units for clearer speech.
    """
    if not text:
        return ""
    
    import re
    text = str(text)

    # --- 1. Filter out internal Reasoning/CoT Artifacts ---
    # These often leak into LLM messages (e.g., "Step 1: ...")
    noise_patterns = [
        r'Step\s*\d+[:\-.]?', r'Reasoning[:\-.]?', r'Assessment[:\-.]?',
        r'Confidence[:\-.]?', r'Grounding[:\-.]?', r'Status[:\-.]?',
        r'Patient[:\-.]?', r'Drug[:\-.]?', r'Extracted[:\-.]?',
        r'Analysis[:\-.]?'
    ]
    for pattern in noise_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)

    # --- 2. Medical Jargon Translation Map (Elder-Friendly) ---
    # Note: Focus on abbreviations commonly found in "Usage" fields
    JARGON_MAP = {
        # Latin Abbreviations
        r'\bQD\b': 'ä¸€å¤©åƒä¸€æ¬¡',
        r'\bBID\b': 'ä¸€å¤©åƒå…©æ¬¡',
        r'\bTID\b': 'ä¸€å¤©åƒä¸‰æ¬¡',
        r'\bQID\b': 'ä¸€å¤©åƒå››æ¬¡',
        r'\bHs\b': 'ç¡å‰åƒ',
        r'\bQHS\b': 'ç¡å‰åƒ',
        r'\bPRN\b': 'å¾ˆä¸èˆ’æœçš„æ™‚å€™æ‰åƒ',
        r'\bac\b': 'é£¯å‰åƒ',
        r'\bpc\b': 'é£¯å¾Œåƒ',
        r'\bPO\b': 'å£æœ',
        r'\bSTAT\b': 'ç«‹åˆ»åƒ',
        r'\bq6h\b': 'æ¯å…­å€‹å°æ™‚åƒä¸€æ¬¡',
        r'\bq8h\b': 'æ¯å…«å€‹å°æ™‚åƒä¸€æ¬¡',
        r'\bq12h\b': 'æ¯åäºŒå€‹å°æ™‚åƒä¸€æ¬¡',
        
        # Common English placeholders
        r'\bas\s+directed\b': 'ç…§é†«ç”Ÿçš„å©å’åƒ',
        r'\bas\s*needed\b': 'ä¸èˆ’æœçš„æ™‚å€™æ‰åƒ',
        
        # Units (to avoid speech engines saying "m-g")
        r'\bmg\b': 'æ¯«å…‹',
        r'\bml\b': 'æ¯«å‡',
        r'\bkg\b': 'å…¬æ–¤',
        
        # --- Standard Taiwan Normalization (Elder-Friendly via Clarity) ---
        r'(\d)\s*æ¬¡': r'\1æ¬¡',
        r'1æ¬¡': 'ä¸€æ¬¡',
        r'2æ¬¡': 'å…©æ¬¡',
        r'3æ¬¡': 'ä¸‰æ¬¡',
        r'4æ¬¡': 'å››æ¬¡',
        r'1é¡†': 'ä¸€é¡†',
        r'2é¡†': 'å…©é¡†',
        r'3é¡†': 'ä¸‰é¡†',
        r'4é¡†': 'å››é¡†',
        r'1éŒ ': 'ä¸€éŒ ', # Restore éŒ 
        r'2éŒ ': 'å…©éŒ ',
        r'3éŒ ': 'ä¸‰éŒ ',
        r'4éŒ ': 'å››éŒ ',
    }
    
    # é‡å°å¤šåœ‹èªè¨€å¯ä»¥æ“´å……æ­¤ Map (ç›®å‰é è¨­æ”¯æ´ä¸­è‹±æ··è®€å„ªåŒ–)
    for eng, local in JARGON_MAP.items():
        text = re.sub(eng, local, text, flags=re.IGNORECASE)

    # --- 3. UI/Markdown Artifact Removal ---
    # Remove JSON syntax
    text = re.sub(r'[{}"\[\]]', '', text)
    # Remove URLs
    text = re.sub(r'http[s]?://\S+', '', text)
    # Remove Markdown bold/italic
    text = re.sub(r'[*_#]', '', text)
    # Remove Emojis & excessive symbols (to prevent engine stutters)
    text = re.sub(r'[âš ï¸âœ…ğŸ”´ğŸŸ¡ğŸŸ¢â“ğŸš¨â›”ğŸš«]', '', text)
    
    # Final cleanup of spacing
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()

def check_drug_interaction(drug_a, drug_b):
    """
    ğŸ” Offline Drug Interaction Check (Local Knowledge Graph)
    """
    if not drug_a or not drug_b or "æœªçŸ¥" in str(drug_a) or "æœªçŸ¥" in str(drug_b):
        return "âš ï¸ è«‹è¼¸å…¥æœ‰æ•ˆçš„è—¥å“åç¨±"
    
    # High-risk interaction pairs (Hardcoded Safety Rules)
    HIGH_RISK_PAIRS = {
        ("warfarin", "aspirin"): "âŒ é«˜é¢¨éšªï¼å…©ç¨®æŠ—å‡è¡€è—¥ä½µç”¨æœƒå¤§å¹…å¢åŠ å‡ºè¡€é¢¨éšª",
        ("warfarin", "plavix"): "âŒ é«˜é¢¨éšªï¼å…©ç¨®æŠ—å‡è¡€è—¥ä½µç”¨æœƒå¤§å¹…å¢åŠ å‡ºè¡€é¢¨éšª",
        ("aspirin", "plavix"): "âš ï¸ è­¦å‘Šï¼šé›™é‡æŠ—è¡€å°æ¿è—¥ç‰©éœ€é†«å¸«è©•ä¼°",
        ("metformin", "glibenclamide"): "âš ï¸ æ³¨æ„ï¼šå…©ç¨®é™è¡€ç³–è—¥ä½µç”¨éœ€ç›£æ¸¬ä½è¡€ç³–",
        ("panadol", "alcohol"): "âŒ å±éšªï¼æ™®æ‹¿ç–¼é…é…’æœƒé€ æˆè‚è‡Ÿæå‚·"
    }
    
    # Normalize drug names
    a_lower = str(drug_a).lower().strip()
    b_lower = str(drug_b).lower().strip()
    
    # Check both orderings
    pair1 = (a_lower, b_lower)
    pair2 = (b_lower, a_lower)
    
    if pair1 in HIGH_RISK_PAIRS:
        return f"ğŸš¨ **äº¤äº’ä½œç”¨è­¦ç¤º**\n\n{HIGH_RISK_PAIRS[pair1]}\n\nå»ºè­°ï¼šè«®è©¢é†«å¸« or è—¥å¸«"
    elif pair2 in HIGH_RISK_PAIRS:
        return f"ğŸš¨ **äº¤äº’ä½œç”¨è­¦ç¤º**\n\n{HIGH_RISK_PAIRS[pair2]}\n\nå»ºè­°ï¼šè«®è©¢é†«å¸« or è—¥å¸«"
    
    return f"âœ… **é›¢ç·šæª¢æŸ¥çµæœ**\n\n{drug_a} èˆ‡ {drug_b} åœ¨æœ¬åœ°è³‡æ–™åº«ä¸­æœªç™¼ç¾å·²çŸ¥çš„åš´é‡äº¤äº’ä½œç”¨ã€‚\n\nâš ï¸ æ³¨æ„ï¼šæ­¤ç‚ºé›¢ç·šæª¢æŸ¥ï¼Œå»ºè­°ä»è«®è©¢å°ˆæ¥­è—¥å¸«ã€‚"

def parse_json_from_response(response_text):
    """
    V7.0 Robust Parser: Native json.loads with Regex Extraction
    Supports: null, true, false, and multi-line structures
    """
    if not response_text:
        return None, "Empty response"
        
    try:
        # 1. å˜—è©¦æå– markdown å€å¡Šå…§çš„ JSON (ä½¿ç”¨ re.DOTALL ç¢ºä¿è·¨è¡ŒåŒ¹é…)
        match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
        json_str = match.group(1) if match else response_text

        # 2. çµ‚æ¥µé˜²ç·šï¼šå¦‚æœ VLM å¿˜è¨˜å¯«å¾Œé¢çš„ ```ï¼Œç›´æ¥æŠ“å–ç¬¬ä¸€å°å¤§æ‹¬è™Ÿ (Greedy Match)
        if not match:
            match_bracket = re.search(r'\{.*\}', json_str, re.DOTALL)
            if match_bracket:
                json_str = match_bracket.group(0)

        # 3. æ¸…ç†èˆ‡è§£æ (åŸç”Ÿæ”¯æ´ true/false/null)
        json_str = json_str.strip()
        data = json.loads(json_str)
        
        # [V27 Fix] Unwrap "parsed" if model nested it
        if "parsed" in data and isinstance(data["parsed"], dict):
            data = data["parsed"]
        return data, None
        
    except Exception as e:
        # Strategy 2: Fallback to literal_eval for single quote messes (legacy support)
        try:
            # æ›¿æ›ç‚º Python èªæ³•
            eval_str = json_str.replace("true", "True").replace("false", "False").replace("null", "None")
            data = ast.literal_eval(eval_str)
            if isinstance(data, dict):
                if "parsed" in data and isinstance(data["parsed"], dict):
                    data = data["parsed"]
                return data, None
        except:
            pass
            
        print(f"âš ï¸ JSON è§£æå¤±æ•—: {e}\nåŸå§‹æ–‡å­—ç‰‡æ®µ: {response_text[:100]}...")
        return None, f"Parsing failed: {str(e)}"

def normalize_dose_to_mg(dose_str):
    """
    ğŸ§ª [Canonical] Normalize raw dosage string to milligrams (mg)
    Handles: "500 mg", "0.5 g", "1000 mcg"
    Returns: (list_of_mg_values, is_valid_conversion)
    """
    if not dose_str: return [], False
    s_full = str(dose_str).lower().replace(",", "").replace(" ", "")
    parts = re.split(r'[/\+]', s_full)
    results = []
    for s in parts:
        if not s: continue
        try:
            # [P0 Fix] åŠ å…¥ é¡†/éŒ /ç²’/tablet/capsule çš„è¾¨è­˜
            match = re.search(r'([\d\.]+)(mg|g|mcg|ug|ml|æ¯«å…‹|å…¬å…‹|é¡†|éŒ |ç²’|tablet|capsule)', s)
            val = 0.0
            if not match:
                 nums = re.findall(r'\d*\.?\d+', s)
                 if nums: 
                     val_candidates = [float(n) for n in nums]
                     val = max(val_candidates)
                     is_decimal = (val % 1 != 0)
                     high_risk_keywords = ["warfarin", "glimepiride", "bisoprolol", "coumadin", "mg"]
                     is_likely_dose = any(k in s.lower() for k in high_risk_keywords)
                     if val < 10 and not is_decimal and not is_likely_dose: 
                         continue 
                 else:
                     continue
            else:
                val = float(match.group(1))
                unit = match.group(2)
                if unit in ['g', 'å…¬å…‹']: val *= 1000.0
                elif unit in ['mcg', 'ug']: val /= 1000.0
                elif unit in ['é¡†', 'éŒ ', 'ç²’', 'tablet', 'capsule']:
                    # [P0 Fix] è‹¥ç‚ºå–®ç´”é¡†æ•¸ï¼Œå‡è¨­è‹¥å¤§æ–¼ç­‰æ–¼ 4 é¡†å³ç‚ºæ½›åœ¨ç•°å¸¸ (å‚³å›æ¥µå¤§å€¼ 9999.0 è§¸ç™¼æ””æˆª)
                    if val >= 4: 
                        val = 9999.0 
                    else: 
                        continue # è‹¥åªæœ‰ 1-2 é¡†ä¸”ç„¡ mg è³‡è¨Šï¼Œæ”¾è¡Œäº¤ç”±å…¶ä»–æ©Ÿåˆ¶æª¢æŸ¥
            results.append(val)
        except: continue
    
    # [P0 Emergency Fix] Multiplier Detection (5X, 10X, 5å€)
    if not results:
        multiplier_match = re.search(r'(\d+)\s*(x|å€|times|normal)', dose_str.lower())
        if multiplier_match:
            try:
                mult = float(multiplier_match.group(1))
                if mult >= 2:
                    return [9999.0], True # Return extreme value to force HIGH_RISK
            except: pass
            
    return results, bool(results)

def check_hard_safety_rules(extracted_data, voice_context=""):
    """
    [Canonical] Centralized Hard Rule Engine (Single Source of Truth)
    Returns: (is_triggered, status, reasoning)
    """
    try:
        actual_data = extracted_data
        if "extracted_data" in extracted_data and isinstance(extracted_data["extracted_data"], dict):
            actual_data = extracted_data["extracted_data"]
            
        patient = actual_data.get("patient", {}) if isinstance(actual_data.get("patient"), dict) else {}
        drug = actual_data.get("drug", {}) if isinstance(actual_data.get("drug"), dict) else {}
        raw_drug_name = drug.get("name") or actual_data.get("drug_name") or ""
        raw_drug_zh = drug.get("name_zh") or ""
        drug_name = (str(raw_drug_name).lower() + " " + str(raw_drug_zh).lower()).strip()
        raw_age = patient.get("age") or actual_data.get("patient_age") or "0"
        
        # ğŸ›¡ï¸ [Hardening] å®‰å…¨æå–å¹´é½¡æ•¸å­—ï¼Œé˜²ç¦¦ "82æ­²" æˆ– "" ç­‰ç•°å¸¸å­—ä¸²
        age_str = str(raw_age)
        age_digits = re.sub(r'\D', '', age_str)
        try:
            age_val = int(age_digits) if age_digits else 0
        except:
            age_val = 0 # ç¢ºä¿å´©æ½°æ™‚é€€å›åˆ° 0ï¼Œè§¸ç™¼ MISSING_DATA æ””æˆª
            
        # ğŸ›¡ï¸ [FAIL-SAFE] Check for missing age on high-risk geriatric drugs
        # å¦‚æœå¹´é½¡ç‚º 0 (è§£æå¤±æ•—æˆ–æ¼å¤±)ï¼Œé‡å° Beers Criteria é«˜é¢¨éšªè—¥ç‰©å¼·åˆ¶æ””æˆª
        if age_val == 0:
            high_risk_elderly_drugs = ["aspirin", "bokey", "zolpidem", "stilnox", "metformin", "glucophage"]
            if any(d in drug_name for d in high_risk_elderly_drugs):
                return True, "MISSING_DATA", "â›” HARD RULE: æ­¤è—¥ç‰©å°é«˜é½¡è€…æœ‰é«˜åº¦é¢¨éšªï¼Œä½†ç³»çµ±ç„¡æ³•è®€å–æˆ–ç¼ºä¹ç—…æ‚£å¹´é½¡è³‡æ–™ï¼ŒåŸºæ–¼å®‰å…¨è€ƒé‡å¼·åˆ¶é€€å›äººå·¥æ ¸å°ã€‚"
            
        # ğŸ›¡ï¸ [RED TEAM FIX] èªéŸ³å‡ºè¡€è­·æ¬„ (Voice Guardrail)
        # ğŸ›¡ï¸ [RED TEAM FIX] èªéŸ³å‡ºè¡€è­·æ¬„ (Voice Guardrail) & [DEEP FIX] Allergy/Emergency
        bleeding_keywords = ["bleed", "blood", "hemorrhage", "black stool", "tarry stool", "bruising", "æµè¡€", "å‡ºè¡€", "é»‘ä¾¿", "è¡€å°¿", "ç˜€é’", "bruise"]
        anticoagulants = ["warfarin", "coumadin", "xarelto", "rivaroxaban", "dabigatran", "eliquis", "apixaban", "edoxaban", "aspirin", "bokey", "plavix", "clopidogrel"]
        
        allergy_keywords = ["allergic", "allergy", "anaphylaxis", "éæ•", "èµ·ç–¹", "è…«èµ·ä¾†", "asthma", "æ°£å–˜"]
        emergency_keywords = ["chest pain", "suicide", "stroke", "crushing pain", "èƒ¸ç—›", "æƒ³ä¸é–‹", "ä¸­é¢¨", "å‘¼å¸å›°é›£"]
        
        voice_lower = str(voice_context).lower()
        
        # 1. Emergency Protocol (Hard Stop) - Zone 1
        if any(k in voice_lower for k in emergency_keywords):
             return True, "HIGH_RISK", "â›” CRITICAL EMERGENCY: User reported life-threatening symptoms (Chest Pain/Suicide/Stroke). CALL 119."

        # 2. Bleeding Check - Zone 1
        if any(k in voice_lower for k in bleeding_keywords):
            if any(d in drug_name for d in anticoagulants):
                return True, "HIGH_RISK", "â›” CRITICAL: Patient reported BLEEDING while on Anticoagulant/Antiplatelet. Immediate Medical Attention Required."

        # 3. Allergy Check (Generic) - Zone 3
        if any(k in voice_lower for k in allergy_keywords):
             return True, "WARNING", "âš ï¸ ALLERGY ALERT: Patient voice note mentions 'Allergy/Adverse Reaction'. Pharmacist verification required."

        raw_dose = str(drug.get("dose") or drug.get("dosage") or actual_data.get("dosage") or "0")
        mg_vals, _ = normalize_dose_to_mg(raw_dose)

        for mg_val in mg_vals:
            if age_val >= 80 and ("glu" in drug_name or "metformin" in drug_name or "glucophage" in drug_name):
                if mg_val > 1000: return True, "PHARMACIST_REVIEW_REQUIRED", f"â›” HARD RULE: Geriatric Max Dose Exceeded (Metformin {mg_val}mg > 1000mg)"
            elif age_val >= 65 and ("stilnox" in drug_name or "zolpidem" in drug_name):
                if mg_val > 5: return True, "HIGH_RISK", f"â›” HARD RULE: BEERS CRITERIA (Zolpidem {mg_val}mg > 5mg). High fall risk."
            elif age_val >= 60 and ("aspirin" in drug_name or "bokey" in drug_name or "asa" in drug_name):
                # [AGS Beers 2023 Update] Avoid for primary prevention in adults 60+
                if mg_val > 325: 
                    return True, "HIGH_RISK", f"â›” HARD RULE: High Dose Aspirin ({mg_val}mg) for elderly (Age {age_val}). Extreme GI Bleeding risk."
                else:
                    return True, "PHARMACIST_REVIEW_REQUIRED", f"âš ï¸ AGS Beers Criteria 2023: Avoid Aspirin for primary prevention in adults 60+ due to major bleeding risk. Verify if intended for secondary prevention."
            elif "lipitor" in drug_name or "atorvastatin" in drug_name:
                if mg_val > 80: return True, "HIGH_RISK", f"â›” HARD RULE: Atorvastatin Safety Limit ({mg_val}mg > 80mg)."
            elif "diovan" in drug_name or "valsartan" in drug_name:
                if mg_val > 320: return True, "HIGH_RISK", f"â›” HARD RULE: Valsartan Safety Limit ({mg_val}mg > 320mg)."
            elif "panadol" in drug_name or "acetaminophen" in drug_name:
                if mg_val > 1000: return True, "HIGH_RISK", f"â›” Acetaminophen Overdose: Single dose {mg_val}mg exceeds safe limit (1000mg)."
                elif mg_val >= 300: return True, "PASS", f"â„¹ï¸ Acetaminophen Reminder: General safe limit for adults is 4000mg/day. Consult your doctor for your specific limit."
            # V10.0: Added check for potassium if on ACE inhibitor
            elif "lisinopril" in drug_name and "potassium" in drug_name:
                return True, "WARNING", "âš ï¸ POTENTIAL INTERACTION: Lisinopril + Potassium supplement may cause hyperkalemia."
            
            # V12.0 Round 120.2: Separate Warfarin and Aspirin thresholds (CRITICAL FIX)
            # Bug: ä¹‹å‰å°‡ Aspirin 100mg èª¤åˆ¤ç‚ºéé‡ï¼Œä½†é€™æ˜¯æ­£å¸¸å¿ƒè¡€ç®¡é é˜²åŠ‘é‡ï¼
            elif "warfarin" in drug_name or "coumadin" in drug_name:
                # Warfarin: è€å¹´äººç¶­æŒåŠ‘é‡é€šå¸¸ 3-5mgï¼Œ>10mg ç–‘ä¼¼å°æ•¸é»éŒ¯èª¤
                if mg_val > 10: 
                    return True, "HIGH_RISK", f"â›” CRITICAL OVERDOSE RISK: Warfarin {mg_val}mg exceeds standard safety limits (typical elderly dose: 3-5mg). Check for decimal error."
            elif any(noac in drug_name for noac in ["rivaroxaban", "xarelto", "dabigatran", "pradaxa", "apixaban", "eliquis", "edoxaban"]):
                # NOACs: åŠ‘é‡ç•°å¸¸æª¢æ¸¬ï¼ˆé€™äº›è—¥ç‰©æœ‰å›ºå®šåŠ‘é‡ï¼‰
                if mg_val > 30:  # Rivaroxaban æœ€é«˜ 20mg, Apixaban æœ€é«˜ 10mg
                    return True, "HIGH_RISK", f"â›” CRITICAL: NOAC dose {mg_val}mg exceeds maximum approved dose."
            # âœ… Aspirin 60+ logic consolidated above (Line 882)
            elif age_val >= 65 and ("plavix" in drug_name or "clopidogrel" in drug_name):
                # Clopidogrel: æ¨™æº–åŠ‘é‡ 75mgï¼Œ> 75mg éœ€ç¢ºèª
                if mg_val > 75:
                    return True, "WARNING", f"âš ï¸ Clopidogrel {mg_val}mg exceeds standard dose (75mg). Verify prescription."
            
            # [P0 Emergency Fix] General Extreme Dose Sentinel (Sent from normalize_dose_to_mg)
            if mg_val >= 9000:
                return True, "HIGH_RISK", f"â›” CRITICAL: Extreme or multiplier dosage detected ({raw_dose}). Potential life-threatening overdose."

            # [P0 Emergency Fix] Bisoprolol (Concor) Geriatric Guardrail
            if age_val >= 65 and ("bisoprolol" in drug_name or "concor" in drug_name):
                if mg_val > 10: # Standard max for elderly is often 5-10mg
                    return True, "HIGH_RISK", f"â›” HARD RULE: Geriatric Bisoprolol safety limit exceeded ({mg_val}mg > 10mg)."

        # [P0 Emergency Fix] Abnormality Keywords in Dose
        raw_dose_lower = str(raw_dose).lower()
        abnormal_keywords = ["normal", "å€", "excessive", "extreme", "abnormal", "åŠ‘é‡ç•°å¸¸", "èª¿æ•´"]
        if any(kw in raw_dose_lower for kw in abnormal_keywords) and ("x" in raw_dose_lower or re.search(r'\d+', raw_dose_lower)):
             return True, "HIGH_RISK", f"â›” CRITICAL: Non-standard high-risk dosage detected: '{raw_dose}'"
        
        # [P0 Emergency Fix] Dangerous Frequency Detection (Q1H, æ¯å°æ™‚)
        usage_lower = str(actual_data.get("usage", "")).lower()
        if any(q in usage_lower for q in ["q1h", "q2h", "1å°æ™‚", "2å°æ™‚", "every 1 hour", "every hour"]):
            # Oral medications should never be Q1H
            return True, "HIGH_RISK", f"â›” CRITICAL FREQUENCY: Dosing every 1-2 hours ({usage_lower}) is highly abnormal and dangerous for oral medication."
                
    except Exception as e:
        print(f"âš ï¸ Hard Rule Check Error: {e}")
    return False, None, None

def logical_consistency_check(extracted_data, safety_analysis=None, voice_context=""):
    """
    [Canonical] Logical Consistency Check (Neuro-Symbolic)
    Unifies logic from app.py and agent_engine.py.
    Returns: (is_passed, message, logs)
    """
    logs = []
    issues = []

    # 1. Parameter Normalization
    actual_data = extracted_data
    if "extracted_data" in extracted_data:
        actual_data = extracted_data["extracted_data"]
        if safety_analysis is None:
            safety_analysis = extracted_data.get("safety_analysis", {})

    if safety_analysis is None:
        safety_analysis = {}

    # 2. Schema Validation
    patient = actual_data.get("patient", {})
    drug = actual_data.get("drug", {})
    
    if not isinstance(patient, dict) or not isinstance(drug, dict):
        # Fallback for flat structure
        patient = {"age": actual_data.get("patient_age", 0)}
        drug = {"name": actual_data.get("drug_name", ""), "dose": actual_data.get("dosage", "")}

    # 3. Age & Hard Rules (Geriatric Guardrails)
    try:
        raw_age = patient.get("age") or 0
        age_val = int(raw_age)
        if age_val > 120: issues.append(f"Invalid Age: {age_val}")
        if 0 < age_val < 18: issues.append(f"Pediatric case ({age_val}) requires manual review")
    except:
        age_val = 0

    # Trigger Central Hard Rules
    is_triggered, rule_status, rule_reason = check_hard_safety_rules(actual_data, voice_context=voice_context)
    if is_triggered:
        # [P0 Fix] åŒ…å«å¯©æ ¸è¦æ±‚èˆ‡è­¦å‘Šï¼Œé˜²æ­¢è¢«ç•¶æˆæ™®é€š Note æ”¾è¡Œ
        if rule_status in ["HIGH_RISK", "PHARMACIST_REVIEW_REQUIRED", "WARNING"]:
            issues.append(rule_reason)
        else:
            logs.append(f"Safety Note: {rule_reason}")

    # 4. [P0 Emergency Fix] Contradictory Reasoning Check (VLM Guard)
    reasoning_lower = str(safety_analysis.get("reasoning", "")).lower()
    negative_medical_terms = ["adjustment needed", "excessive", "high dose", "overdose", "abnormal", "å±éšª", "éé«˜", "éé‡", "ä¸å»ºè­°"]
    if any(k in reasoning_lower for k in negative_medical_terms):
        if safety_analysis.get("status") == "PASS":
            issues.append(f"â›” SAFETY OVERRIDE: Reasoning indicated risk ('{reasoning_lower}') but status was PASS. Forcing review.")

    # ğŸŸ¢ [FIX] Precedence: Critical Safety Rules > Unknown Drug
    # Check immediately after Hard Rules to prevent masking
    critical_issues = [i for i in issues if "CRITICAL" in i or "HARD RULE" in i or "HIGH_RISK" in i]
    if critical_issues:
            return False, f"â›” CRITICAL SAFETY HALT: {'; '.join(critical_issues)}", logs

    # 4. Drug Knowledge Base Presence (Anti-Hallucination)
    drug_name = drug.get("name") or actual_data.get("drug_name") or ""
    if drug_name:
        is_known = offline_db_lookup(drug_name)
        if not is_known:
            if "unknown" in str(drug_name).lower():
                return True, "âš ï¸ UNKNOWN_DRUG detected. Manual Review Required.", logs
            else:
                issues.append(f"Drug not in knowledge base: {drug_name}")

    # 5. Reasoning Consistency (VLM Audit)
    status = safety_analysis.get("status", "")
    reasoning = safety_analysis.get("reasoning", "")
    if status == "HIGH_RISK" and drug_name and drug_name.lower() not in str(reasoning).lower():
        issues.append("Safety Reasoning does not mention the flagged drug name.")

    if issues:
        # Prevent infinite retry for unknown drugs if flagged
        if any("not in knowledge base" in issue for issue in issues):
            return True, f"âš ï¸ UNKNOWN_DRUG detected: {drug_name}. Manual Review Required.", logs
        return False, f"Logic Consistency Failed: {'; '.join(issues)}", logs

    return True, "Logic Consistent", logs

def offline_db_lookup(drug_name):
    """
    Simulates checking against a trusted offline database.
    Returns True if drug exists in approved list.
    """
    try:
        # [V8 Fix] Robust Cleaning before Lookup
        def clean_name_internal(name):
            name = re.sub(r'\s*\d+\.?\d*\s*(mg|g|mcg|ug|ml|æ¯«å…‹|å…¬å…‹)\b', '', str(name), flags=re.IGNORECASE)
            name = re.sub(r'\s*\([^)]*\)', '', name).strip().lower()
            return name
        
        # [V11.1] Critical Fix: Check Safe Substrings FIRST (Before cleaning strips essential chars)
        # Uses global SAFE_SUBSTRINGS defined at module level
        
        # Case-insensitive check on raw name first
        if any(safe in str(drug_name).lower() for safe in SAFE_SUBSTRINGS):
            return True

        target = clean_name_internal(drug_name)
        
        db = DRUG_DATABASE
        candidates = []
        for category in db.values():
            for item in category:
                if target in [item['name_en'].lower(), item['name_zh'].lower(), item['generic'].lower()]:
                    return True
                candidates.append(item['name_en'].lower())
                candidates.append(item['generic'].lower())

        if target in DRUG_ALIASES:
            return True
        candidates.extend(DRUG_ALIASES.keys())
        
        import difflib
        matches = difflib.get_close_matches(target, candidates, n=1, cutoff=0.7)
        if matches:
            return True

        if any(safe in target for safe in SAFE_SUBSTRINGS):
            return True

        return False
    except ImportError:
        SAFE_LIST = ["warfarin", "aspirin", "furosemide", "metformin", "amlodipine", 
                        "plavix", "stilnox", "lipitor", "crestor", "bisoprolol",
                        "bokey", "licodin", "diovan", "xanax", "valium", "panadol", "acetaminophen"]
        return any(d in drug_name.lower() for d in SAFE_LIST)

def safety_critic_tool(json_output):
    """
    The 'Callable Tool' that acts as the Critic (Rule-Based).
    """
    import re
    try:
        data = json_output if isinstance(json_output, dict) else json.loads(json_output)
    
        extracted = data.get("extracted_data", {})
        raw_name = extracted.get("drug", {}).get("name", "")
        if not raw_name: raw_name = str(extracted.get("drug", ""))
    
        # [V8 Fix] Use broad cleaning (mg, g, mcg, ug, ml, tablets, etc.)
        clean_name = re.sub(r'\s*\d+\.?\d*\s*(mg|g|mcg|ug|ml|æ¯«å…‹|å…¬å…‹|é¡†|tablets?)\b', '', raw_name, flags=re.IGNORECASE)
        clean_name = re.sub(r'\s*\([^)]*\)', '', clean_name).strip()
    
        # Rule 1: Conflict Check
        if "Warfarin" in clean_name and "Aspirin" in clean_name:
                return False, "CRITICAL INTERACTION: Warfarin and Aspirin detected together. Immediate Verification Needed."

        # Rule 2: Hallucination Check
        if clean_name and not("unknown" in clean_name.lower()):
            if not offline_db_lookup(clean_name):
                if not offline_db_lookup(raw_name):
                    return False, f"Drug '{raw_name}' (Cleaned: '{clean_name}') not found in approved local database (Possible Hallucination)."

        # Rule 3: Dosage Sanity Check
        dose = extracted.get("drug", {}).get("dose", "")
        if dose and any(x in dose for x in ["2000mg", "7000mg"]): # 2000mg is allowed for Metformin, but suspicious if not checked
            pass 

        return True, "Logic Sound."
    
    except Exception as e:
        return False, f"Critic Tool Error: {str(e)}"

def check_is_prescription(response_text):
    """
    ğŸ›¡ï¸ [Round 126] Enhanced OOD Detection - Reject non-medical images
    é˜²æ­¢ ETFã€é¢¨æ™¯ç…§ã€è²“å’ªç…§è¢«å¼·è¡Œè§£é‡‹æˆè—¥ç‰©
    """
    # æ ¸å¿ƒé†«ç™‚é—œéµå­—ï¼ˆå¿…é ˆåŒ…å«é€™äº›æ‰ç®—é†«ç™‚å…§å®¹ï¼‰
    CORE_MEDICAL_KEYWORDS = [
        "è—¥", "drug", "medicine", "pill", "tablet", "capsule", 
        "mg", "mcg", "g", "ml",  # åŠ‘é‡å–®ä½
        "æœç”¨", "æ—©æ™š", "é£¯å¾Œ", "ç¡å‰", "use", "take", "daily",
        "indication", "side effect", "warning", "å‰¯ä½œç”¨", "é©æ‡‰ç—‡",
        "pharmacy", "hospital", "è¨ºæ‰€", "é†«é™¢", "prescription",
        "patient", "dose", "dosage", "medication", "æ²»ç™‚"
    ]
    
    # æ’é™¤é—œéµå­—ï¼ˆå¦‚æœåŒ…å«é€™äº›ï¼Œå¤§æ¦‚ç‡ä¸æ˜¯è—¥å–®ï¼‰
    EXCLUDE_KEYWORDS = [
        "etf", "exchange traded fund", "stock", "æŠ•è³‡", "åŸºé‡‘",
        "0050", "2330", "è‚¡ç¥¨", "trading", "portfolio"
    ]
    
    response_lower = str(response_text).lower()
    
    # æª¢æŸ¥æ’é™¤é—œéµå­—
    for exclude_kw in EXCLUDE_KEYWORDS:
        if exclude_kw in response_lower:
            return False
    
    # è¨ˆç®—é†«ç™‚é—œéµå­—å‘½ä¸­æ•¸
    keyword_count = sum(1 for kw in CORE_MEDICAL_KEYWORDS if kw.lower() in response_lower)
    
    # é–€æª»ï¼šè‡³å°‘è¦å‘½ä¸­ 2 å€‹é†«ç™‚é—œéµå­—æ‰ç®—æ˜¯è™•æ–¹ç®‹ (åŸç‚º 4ï¼Œé‡å°çŸ­å›è¦†é€²è¡Œå„ªåŒ–)
    # (ä¾‹å¦‚åªæœ‰ "Aspirin 100mg" ä¹Ÿæ‡‰è©²é)
    if keyword_count >= 2:
        return True
    
    return False
