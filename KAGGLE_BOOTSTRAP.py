"""
================================================================================
ğŸ¥ AI Pharmacist Guardian - Kaggle Bootstrap (V10.0 Clean Slate)
================================================================================
ğŸ“‹ æˆ°ç•¥ç¸½ç›£é©—è­‰ (Verified Strategy):
   1. [NUKE] æš´åŠ›ç§»é™¤æ‰€æœ‰ PyTorch èˆ‡ HuggingFace ç›¸é—œå¥—ä»¶ï¼Œæ¸…é™¤æ®˜ç•™ã€‚
   2. [PAVE] å¾ PyPI ä¸‹è¼‰å®˜æ–¹é©—è­‰éçš„ã€Œé»ƒé‡‘ä¸‰è§’ã€ç‰ˆæœ¬ã€‚
   3. [VERIFY] å®‰è£å¾Œç«‹å³åŸ·è¡Œè‡ªæˆ‘æª¢æ¸¬ï¼Œç¢ºä¿ import æˆåŠŸã€‚
================================================================================
"""

# %%
# ============================================================================
# STEP 0: ç’°å¢ƒé‡ç½®èˆ‡èªè­‰
# ============================================================================
import os
import sys
import subprocess
from kaggle_secrets import UserSecretsClient

print("=" * 80)
print("ğŸ¥ AI Pharmacist Guardian - Bootstrap (V10.0 Clean Slate)")
print("=" * 80)

# 1. è®€å–é‡‘é‘°
user_secrets = UserSecretsClient()
print("\n[1/6] è®€å–èªè­‰é‡‘é‘°...")
try:
    gh_token = user_secrets.get_secret("GITHUB_TOKEN")
    hf_token = user_secrets.get_secret("HUGGINGFACE_TOKEN")
    print("   âœ… é‡‘é‘°è®€å–æˆåŠŸ")
except:
    print("   âŒ é‡‘é‘°æœªè¨­å®šï¼è«‹å» Add-ons > Secrets è¨­å®š")
    gh_token = ""
    hf_token = ""

# %%
# ============================================================================
# STEP 1: ä¸‹è¼‰ Repository
# ============================================================================
print("\n[2/6] ä¸‹è¼‰ SilverGuard Repository...")
!rm -rf SilverGuard medgemma_training_data_v5
repo_url = f"https://{gh_token}@github.com/mark941108/SilverGuard.git"
!git clone --depth 1 {repo_url}
%cd SilverGuard
print("   âœ… Repository ä¸‹è¼‰å®Œæˆ")

# %%
# ============================================================================
# STEP 2: è‡ªå‹•ç†±ä¿®å¾© (Hotfix Patch)
# ============================================================================
print("\n[3/6] æ‡‰ç”¨ä»£ç¢¼ç†±ä¿®å¾©...")
patch_code = """
    "QD_breakfast_after": {"code": "QD-PC", "zh": "æ¯æ—¥1æ¬¡ï¼Œæ—©é¤å¾Œæœç”¨", "detail": "æ¯æ—¥æ—©é¤å¾Œ30åˆ†é˜æœç”¨"},
    "QD_meals_with": {"code": "QD-M", "zh": "æ¯æ—¥1æ¬¡ï¼Œéš¨é¤æœç”¨", "detail": "è«‹æ–¼ç”¨é¤æ™‚ä¸€ä½µæœç”¨ä»¥å¢åŠ å¸æ”¶"},
"""
target_file = "SilverGuard_Impact_Research_V8.py"
try:
    with open(target_file, "r", encoding="utf-8") as f:
        content = f.read()
    if '"QD_meals_with":' not in content:
        anchor = '"QD_breakfast_after": {"code": "QD-PC", "zh": "æ¯æ—¥1æ¬¡ï¼Œæ—©é¤å¾Œæœç”¨", "detail": "æ¯æ—¥æ—©é¤å¾Œ30åˆ†é˜æœç”¨"},'
        if anchor in content:
            new_content = content.replace(anchor, patch_code.strip())
            with open(target_file, "w", encoding="utf-8") as f:
                f.write(new_content)
            print("   âœ… ç†±ä¿®å¾©æˆåŠŸ")
    else:
        print("   âœ… ä»£ç¢¼å·²åŒ…å«ä¿®å¾©")
except Exception as e:
    print(f"   âš ï¸ ç†±ä¿®å¾©è·³é: {e}")

# %%
# ============================================================================
# STEP 3: æš´åŠ›æ¸…é™¤èˆŠç’°å¢ƒ (The Nuke)
# ============================================================================
print("\n[4/6] æ­£åœ¨æ¸…ç†è¡çªå¥—ä»¶ (é€™å¯èƒ½éœ€è¦ 1 åˆ†é˜)...")
# å¼·åˆ¶ç§»é™¤æ‰€æœ‰å¯èƒ½è¡çªçš„å¥—ä»¶
!pip uninstall -y torch torchvision torchaudio transformers huggingface_hub sentence-transformers accelerate peft bitsandbytes gradio

# %%
# ============================================================================
# STEP 4: ä¹¾æ·¨å®‰è£ (The Pave) - é»ƒé‡‘ç‰ˆæœ¬çŸ©é™£
# ============================================================================
print("\n[5/6] å®‰è£é»ƒé‡‘ç‰ˆæœ¬çµ„åˆ...")

# 1. ç³»çµ±ä¾è³´
!apt-get update -y && apt-get install -y libespeak1 libsndfile1 ffmpeg

# 2. PyTorch ç”Ÿæ…‹ç³» (åš´æ ¼é–å®šç‰ˆæœ¬)
# Torch 2.5.1 æ˜¯ç›®å‰æœ€ç©©å®šçš„ CUDA 12 ç‰ˆæœ¬
print("   â¬‡ï¸ å®‰è£ PyTorch 2.5.1 Ecosystem...")
!pip install --no-cache-dir torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121

# 3. Hugging Face ç”Ÿæ…‹ç³» (ç›¸å®¹æ€§é–å®š)
print("   â¬‡ï¸ å®‰è£ Hugging Face Stack...")
# Hub 0.27+ è§£æ±º DryRunError
# Transformers 4.48+ è§£æ±º Gemma 2 bug
!pip install -U "huggingface-hub>=0.27.0"
!pip install -U "transformers>=4.48.0"
!pip install -U accelerate bitsandbytes peft datasets

# 4. RAG èˆ‡æ‡‰ç”¨å±¤
print("   â¬‡ï¸ å®‰è£æ‡‰ç”¨å±¤ä¾è³´...")
!pip install -U sentence-transformers faiss-cpu pydub
!pip install -U pillow==11.0.0 librosa soundfile
!pip install -U qrcode[pil] albumentations==1.3.1 opencv-python-headless gTTS edge-tts nest_asyncio pyttsx3

# 5. Gradio (ç¢ºä¿æœ€æ–°)
!pip install -U gradio>=4.0.0

print("   âœ… æ‰€æœ‰ä¾è³´å®‰è£å®Œæˆï¼")

# %%
# ============================================================================
# STEP 5: è‡ªæˆ‘æª¢æ¸¬èˆ‡å•Ÿå‹•
# ============================================================================
print("\n[6/6] ç³»çµ±è‡ªæˆ‘æª¢æ¸¬...")

try:
    import torch
    import torchvision
    import transformers
    import huggingface_hub
    
    print(f"   ğŸ” Torch Version: {torch.__version__}")
    print(f"   ğŸ” Vision Version: {torchvision.__version__}")
    print(f"   ğŸ” Transformers: {transformers.__version__}")
    print(f"   ğŸ” Hub Version: {huggingface_hub.__version__}")
    
    # ç°¡å–®çš„ GPU æª¢æŸ¥
    if torch.cuda.is_available():
        print(f"   ğŸ” GPU Detected: {torch.cuda.get_device_name(0)}")
    else:
        print("   âš ï¸ WARNING: No GPU detected! Inference will be slow.")

except ImportError as e:
    print(f"   âŒ CRITICAL: ç’°å¢ƒæª¢æ¸¬å¤±æ•— - {e}")
    # é€™è£¡ä¸æ‹‹å‡ºéŒ¯èª¤ï¼Œå˜—è©¦ç¹¼çºŒåŸ·è¡Œ

from huggingface_hub import login
login(token=hf_token)

print("\n" + "=" * 80)
print("ğŸš€ å•Ÿå‹• SilverGuard: Impact Research Edition (V10.0 Final)")
print("=" * 80)

%run SilverGuard_Impact_Research_V8.py
