"""
================================================================================
ğŸ¥ AI Pharmacist Guardian - Kaggle Bootstrap (V12.2 Platinum Stable)
================================================================================
ğŸ“‹ æˆ°ç•¥æ›´æ–°å°æ‡‰ (V12.2):
   1. [CRITICAL] å¼·åˆ¶é–å®š Transformers < 5.0.0ã€‚
      åŸå› ï¼šTransformers 5.0.0 å¼•å…¥äº† Gemma 3 æ¶æ§‹ï¼Œå¼·åˆ¶è¦æ±‚ PyTorch >= 2.6.0ã€‚
      ç‚ºäº†ç¶­æŒ T4 ç©©å®šæ€§ (ä½¿ç”¨ PyTorch 2.5.1)ï¼Œå¿…é ˆç¦æ­¢å‡ç´šåˆ° 5.0ã€‚
   2. [LOGIC] ç¶­æŒ Metformin eGFR æª¢æŸ¥é‚è¼¯ã€‚
   3. [COMPLIANCE] ç¶­æŒè—¥å¸«æ³•ç¬¬ 19 æ¢æ¨™ç¤ºã€‚
================================================================================
"""

# %%
# ============================================================================
# STEP 0: ç’°å¢ƒé‡ç½®èˆ‡èªè­‰
# ============================================================================
import os
import sys
import re
from kaggle_secrets import UserSecretsClient

print("=" * 80)
print("ğŸ¥ AI Pharmacist Guardian - Bootstrap (V12.2 Platinum Stable)")
print("=" * 80)

# 1. è®€å–é‡‘é‘°
user_secrets = UserSecretsClient()
print("\n[1/6] è®€å–èªè­‰é‡‘é‘°...")
try:
    gh_token = user_secrets.get_secret("GITHUB_TOKEN")
    hf_token = user_secrets.get_secret("HUGGINGFACE_TOKEN")
    print("   âœ… é‡‘é‘°è®€å–æˆåŠŸ")
except:
    print("   âŒ é‡‘é‘°æœªè¨­å®šï¼è«‹å» Add-ons > Secrets è¨­å®š")
    gh_token = ""
    hf_token = ""

# %%
# ============================================================================
# STEP 1: ä¸‹è¼‰ Repository
# ============================================================================
print("\n[2/6] ä¸‹è¼‰ SilverGuard Repository...")
!rm -rf SilverGuard medgemma_training_data_v5
repo_url = f"https://{gh_token}@github.com/mark941108/SilverGuard.git"
!git clone --depth 1 {repo_url}
%cd SilverGuard
print("   âœ… Repository ä¸‹è¼‰å®Œæˆ")

# %%
# ============================================================================
# STEP 2: åŸ·è¡Œã€Œé–‹è…¦æ‰‹è¡“ã€ (Critical Surgery) - ä¿®å¾©æ‰€æœ‰å·²çŸ¥å•é¡Œ
# ============================================================================
print("\n[3/6] æ­£åœ¨å°ä»£ç¢¼é€²è¡Œå¤–ç§‘æ‰‹è¡“ (V12.2 Logic Updates)...")

target_file = "SilverGuard_Impact_Research_V8.py"

with open(target_file, "r", encoding="utf-8") as f:
    content = f.read()

# --- æ‰‹è¡“ A: ä¿®æ­£ Metformin é‚è¼¯ (Hard Rule -> Missing Data) ---
# å°‡ Metformin > 1000mg çš„ç¡¬æ€§ HIGH_RISK è­¦å‘Šæ”¹ç‚º MISSING_DATA (å¦‚æœå°šæœªä¿®æ”¹)
if 'safety["status"] = "HIGH_RISK"' in content and 'Metformin > 1000mg' in content:
    print("   ğŸ”§ æ‰‹è¡“ A: ä¿®æ­£ Metformin è¦å‰‡ (High Risk -> Missing Data)...")
    content = content.replace(
        'safety["status"] = "HIGH_RISK"',
        'safety["status"] = "MISSING_DATA"'
    ).replace(
        'safety["reasoning"] = "âš ï¸ [System Hard Rule] Metformin æ¯æ—¥åŠ‘é‡è¶…é 1000mgï¼Œå°æ–¼è…åŠŸèƒ½è¡°é€€çš„è€å¹´äººå…·æœ‰é«˜åº¦ä¹³é…¸ä¸­æ¯’é¢¨éšªã€‚"',
        'safety["reasoning"] = "âš ï¸ [AGS Beers Criteria] åµæ¸¬åˆ° Metformin é«˜åŠ‘é‡ï¼Œä½†ç¼ºå°‘è…åŠŸèƒ½æ•¸æ“š(eGFR)ã€‚è«‹ç¢ºèª eGFR > 30 mL/min ä»¥ç¢ºä¿å®‰å…¨ã€‚"'
    )

# --- æ‰‹è¡“ B: è§£é™¤æ­»é– (Disable Gradient Checkpointing) ---
if "gradient_checkpointing=True" in content:
    print("   ğŸ”§ æ‰‹è¡“ B: å¼·åˆ¶é—œé–‰ Gradient Checkpointing (Fix Deadlock)...")
    content = content.replace("gradient_checkpointing=True", "gradient_checkpointing=False")

# --- æ‰‹è¡“ C: é˜²æ­¢ OOM (Reduce Batch Size) ---
content = re.sub(r"per_device_train_batch_size\s*=\s*\d+", "per_device_train_batch_size=1", content)
content = re.sub(r"gradient_accumulation_steps\s*=\s*\d+", "gradient_accumulation_steps=8", content)

# --- æ‰‹è¡“ D: ä¿®å¾©ç¸®æ’éŒ¯èª¤ (Extra Safety) ---
# é‡å° User ä¹‹å‰å›å ±çš„ IndentationError é€²è¡Œé˜²ç¦¦æ€§æª¢æŸ¥
# é›–ç„¶ User èªªå·²ç¶“ä¿®å¾©ï¼Œä½† Bootstrap æ‰‹è¡“å¯èƒ½æœƒå†æ¬¡è§¸ç™¼
# é€™è£¡æˆ‘å€‘ä¸åš Blind Regex Replaceï¼Œç›¸ä¿¡ Git Pull ä¸‹ä¾†çš„ç‰ˆæœ¬å·²ç¶“ä¿®å¾©

# å¯«å›æª”æ¡ˆ
with open(target_file, "w", encoding="utf-8") as f:
    f.write(content)

print("   âœ… V12.2 æ‰‹è¡“å®Œæˆï¼")

# %%
# ============================================================================
# STEP 3: æš´åŠ›æ¸…é™¤èˆŠç’°å¢ƒ (The Nuke)
# ============================================================================
print("\n[4/6] æ¸…ç†è¡çªå¥—ä»¶...")
!pip uninstall -y torch torchvision torchaudio transformers huggingface_hub sentence-transformers accelerate peft bitsandbytes gradio

# %%
# ============================================================================
# STEP 4: ä¹¾æ·¨å®‰è£ (The Pave) - V12.2 ç™½é‡‘ä¾è³´çŸ©é™£
# ============================================================================
print("\n[5/6] å®‰è£ç™½é‡‘ç‰ˆæœ¬çµ„åˆ (PyTorch 2.5.1 + Transformers 4.x)...")

# 1. ç³»çµ±ä¾è³´
!apt-get update -y && apt-get install -y libespeak1 libsndfile1 ffmpeg

# 2. PyTorch 2.5.1 (Stable Golden Config)
print("   â¬‡ï¸ å®‰è£ PyTorch 2.5.1 Ecosystem...")
!pip install --no-cache-dir torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124

# 3. Hugging Face Stack (PINNED VERSION)
# ğŸ”¥ V12.2 CRITICAL FIX: ç¦æ­¢å®‰è£ Transformers 5.0+
print("   â¬‡ï¸ å®‰è£ Hugging Face Stack (Forced Transformers 4.x)...")
!pip install -U "huggingface-hub>=0.26.0"
!pip install -U "transformers>=4.46.0,<5.0.0"
!pip install -U accelerate bitsandbytes peft datasets

# 4. RAG èˆ‡æ‡‰ç”¨å±¤
print("   â¬‡ï¸ å®‰è£æ‡‰ç”¨å±¤ä¾è³´...")
!pip install -U sentence-transformers faiss-cpu pydub
!pip install -U pillow==11.0.0 librosa soundfile
!pip install -U qrcode[pil] albumentations==1.3.1 opencv-python-headless gTTS edge-tts nest_asyncio pyttsx3

# 5. Gradio
!pip install -U gradio>=4.0.0

print("   âœ… æ‰€æœ‰ä¾è³´å®‰è£å®Œæˆï¼")

# %%
# ============================================================================
# STEP 5: å•Ÿå‹•ä¸»ç¨‹å¼
# ============================================================================
print("\n[6/6] ç³»çµ±å•Ÿå‹•...")

from huggingface_hub import login
login(token=hf_token)

print("\n" + "=" * 80)
print("ğŸš€ å•Ÿå‹• SilverGuard: Impact Research Edition (V12.2 Platinum)")
print("=" * 80)

# åŸ·è¡Œ
%run SilverGuard_Impact_Research_V8.py
