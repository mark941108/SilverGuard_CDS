import gradio as gr
import torch
from transformers import AutoModelForImageTextToText, AutoProcessor, BitsAndBytesConfig
from peft import PeftModel
from PIL import Image
import json
import os
import re

# ============================================================================
# üè• AI Pharmacist Guardian - Hugging Face Space Demo
# ============================================================================
# This app provides an interactive demo for the MedGemma Impact Challenge.
# It loads the fine-tuned adapter from Hugging Face Hub (Bonus 1) and runs inference.

# 1. Configuration
# Ensure HUGGINGFACE_TOKEN is set in Space Settings -> Repository secrets
HF_TOKEN = os.environ.get("HUGGINGFACE_TOKEN")

BASE_MODEL = "google/medgemma-1.5-4b-it"
# ‚ö†Ô∏è TODO: Replace with YOUR specific Model ID after running Cell 9
# Example: "yuan-dao/medgemma-pharmacist-guardian-v5"
ADAPTER_MODEL = os.environ.get("ADAPTER_MODEL_ID", "Please_Replace_This_With_Your_Repo_ID")

# V7.1 FIX: Fail fast if ADAPTER_MODEL is not configured
if "Please_Replace" in ADAPTER_MODEL or not ADAPTER_MODEL:
    print("‚ùå CRITICAL: ADAPTER_MODEL_ID not configured!")
    print("   Please set ADAPTER_MODEL_ID in HuggingFace Space Settings > Repository secrets")
    print("   Example: yuan-dao/medgemma-pharmacist-guardian-v5")
    raise ValueError("ADAPTER_MODEL_ID environment variable must be set before deployment.")

print(f"‚è≥ Loading MedGemma Adapter: {ADAPTER_MODEL}...")

# 2. Model Loading
try:
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.float16,
    )

    base_model = AutoModelForImageTextToText.from_pretrained(
        BASE_MODEL, 
        quantization_config=bnb_config,
        device_map="auto",
        token=HF_TOKEN
    )

    model = PeftModel.from_pretrained(base_model, ADAPTER_MODEL, token=HF_TOKEN)
    processor = AutoProcessor.from_pretrained(BASE_MODEL, token=HF_TOKEN)
    print("‚úÖ MedGemma Loaded Successfully!")
except Exception as e:
    print(f"‚ùå Error loading MedGemma: {e}")
    # Fallback for build logs
    base_model = None
    model = None
    processor = None

# ============================================================================
# üé§ MedASR Loading (Second HAI-DEF Model for Bonus Score!)
# ============================================================================
# MedASR: 105M param Medical Speech Recognition (runs on CPU to save GPU for VLM)
MEDASR_MODEL = "google/medasr"
medasr_pipeline = None

try:
    from transformers import pipeline
    print(f"‚è≥ Loading MedASR: {MEDASR_MODEL}...")
    medasr_pipeline = pipeline(
        "automatic-speech-recognition",
        model=MEDASR_MODEL,
        token=HF_TOKEN,
        device="cpu",  # Run on CPU to save GPU VRAM for MedGemma
        torch_dtype=torch.float32
    )
    print("‚úÖ MedASR Loaded Successfully!")
except Exception as e:
    print(f"‚ö†Ô∏è MedASR loading failed (non-critical): {e}")
    medasr_pipeline = None

def transcribe_audio(audio_path):
    """
    Transcribe audio using MedASR (google/medasr).
    Returns: (transcription_text, success_flag)
    """
    if medasr_pipeline is None:
        return "", False
    
    if audio_path is None:
        return "", False
    
    try:
        import librosa
        # Load and resample to 16kHz (MedASR requirement)
        audio, sr = librosa.load(audio_path, sr=16000)
        result = medasr_pipeline({"array": audio, "sampling_rate": 16000})
        transcription = result.get("text", "")
        print(f"üé§ MedASR Transcription: {transcription}")
        return transcription, True
    except Exception as e:
        print(f"‚ö†Ô∏è MedASR transcription failed: {e}")
        return "", False

import spaces # ZeroGPU support


# ============================================================================
# üß† Helper Functions (robust logic synced from Kaggle Notebook)
# ============================================================================

# V6 Fix: Documented Blur Threshold (per Dr. K critique)
BLUR_THRESHOLD = 100

def check_image_quality(image, blur_threshold=BLUR_THRESHOLD):
    """
    Input Validation Gate - Reject blurry images
    Uses Laplacian variance (requires converting PIL to cv2 format)
    V7.1 FIX: Handle RGBA images by converting to RGB first
    """
    try:
        import cv2
        import numpy as np
        
        # V7.1 FIX: Convert RGBA to RGB to prevent OpenCV crash on transparent PNGs
        if image.mode == "RGBA":
            image = image.convert("RGB")
        elif image.mode != "RGB":
            image = image.convert("RGB")
        
        # Convert PIL Image to OpenCV format
        open_cv_image = np.array(image) 
        # Convert RGB to BGR 
        open_cv_image = open_cv_image[:, :, ::-1].copy() 
        
        gray = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        if laplacian_var < blur_threshold:
            return False, f"Image too blurry (score: {laplacian_var:.1f} < {blur_threshold})"
        return True, "Quality OK"
    except Exception as e:
        return True, f"Blur check skipped: {e}"

def check_is_prescription(response_text):
    """OOD Detection - Verify prescription content"""
    prescription_keywords = ["patient", "drug", "dose", "mg", "tablet", "capsule", 
                            "prescription", "pharmacy", "usage", "medication", "Ëó•"]
    response_lower = response_text.lower()
    keyword_count = sum(1 for kw in prescription_keywords if kw.lower() in response_lower)
    
    # V6 Fix: Increased threshold from 2 to 3
    if keyword_count >= 3:
        return True
    return False

# ===== V7 Fix: Drug Aliases Mapping (Fixed reverse lookup bug) =====
# PURPOSE: Allow searching by brand name OR generic name
# FIX: Removed aliases that don't match database (e.g., coumadin when only warfarin exists)
DRUG_ALIASES = {
    "glucophage": "metformin",
    "glucophage xr": "metformin", "fortamet": "metformin", "glumetza": "metformin",
    "amaryl": "glimepiride",
    "januvia": "sitagliptin",
    "norvasc": "amlodipine",
    "concor": "bisoprolol",
    "diovan": "valsartan",
    "stilnox": "zolpidem",
    "imovane": "zopiclone",
    "asa": "aspirin",  # ASA maps to aspirin
    "plavix": "clopidogrel",
    "coumadin": "warfarin",  # Coumadin brand ‚Üí Warfarin
    "lipitor": "atorvastatin",
    "crestor": "rosuvastatin",
}

# ===== Ëó•Áâ©Ë≥áÊñôÂ∫´ (V5 Êì¥ÂÖÖÁâàÔºö12Á®ÆËó•Áâ©) =====
# Sync from KAGGLE_V4_COMPLETE.py Cell 2
DRUG_DATABASE = {
    "Hypertension": [
        {"code": "BC23456789", "name_en": "Norvasc", "name_zh": "ËÑàÂÑ™", "generic": "Amlodipine", "dose": "5mg", "appearance": "ÁôΩËâ≤ÂÖ´ËßíÂΩ¢", "indication": "ÈôçË°ÄÂ£ì", "warning": "Â∞èÂøÉÂßøÂã¢ÊÄß‰ΩéË°ÄÂ£ì", "default_usage": "QD_breakfast_after"},
        {"code": "BC23456790", "name_en": "Concor", "name_zh": "Â∫∑ËÇØ", "generic": "Bisoprolol", "dose": "5mg", "appearance": "ÈªÉËâ≤ÂøÉÂΩ¢", "indication": "ÈôçË°ÄÂ£ì", "warning": "ÂøÉË∑≥ÈÅéÊÖ¢ËÄÖÊÖéÁî®", "default_usage": "QD_breakfast_after"},
        {"code": "BC23456791", "name_en": "Diovan", "name_zh": "ÂæóÂÆâÁ©©", "generic": "Valsartan", "dose": "80mg", "appearance": "Ê∑°Á¥ÖËâ≤Ê©¢ÂúìÂΩ¢", "indication": "ÈôçË°ÄÂ£ì", "warning": "Êá∑Â≠ïÁ¶ÅÁî®", "default_usage": "QD_breakfast_after"},
    ],
    "Diabetes": [
        {"code": "BC11223344", "name_en": "Glucophage", "name_zh": "Â∫´È≠ØÂåñ", "generic": "Metformin", "dose": "500mg", "appearance": "ÁôΩËâ≤Èï∑ÂúìÂΩ¢", "indication": "ÈôçË°ÄÁ≥ñ", "warning": "Èö®È§êÊúçÁî®", "default_usage": "BID_meals_after"},
        {"code": "BC11223345", "name_en": "Amaryl", "name_zh": "Áë™ÁàæËÉ∞", "generic": "Glimepiride", "dose": "2mg", "appearance": "Á∂†Ëâ≤Ê©¢ÂúìÂΩ¢", "indication": "ÈôçË°ÄÁ≥ñ", "warning": "Â∞èÂøÉ‰ΩéË°ÄÁ≥ñ", "default_usage": "QD_breakfast_after"},
        {"code": "BC11223346", "name_en": "Januvia", "name_zh": "‰Ω≥Á≥ñÁ∂≠", "generic": "Sitagliptin", "dose": "100mg", "appearance": "Á±≥Ëâ≤ÂúìÂΩ¢", "indication": "ÈôçË°ÄÁ≥ñ", "warning": "ËÖéÂäüËÉΩ‰∏çÂÖ®ÈúÄË™øÊï¥ÂäëÈáè", "default_usage": "QD_breakfast_after"},
    ],
    "Sedative": [
        {"code": "BC99998888", "name_en": "Stilnox", "name_zh": "‰ΩøËíÇË´æÊñØ", "generic": "Zolpidem", "dose": "10mg", "appearance": "ÁôΩËâ≤Èï∑Ê¢ùÂΩ¢", "indication": "Â§±Áú†", "warning": "ÊúçÁî®ÂæåË´ãÁ´ãÂç≥Â∞±ÂØ¢", "default_usage": "QD_bedtime"},
        {"code": "BC99998889", "name_en": "Imovane", "name_zh": "ÂÆúÁú†ÂÆâ", "generic": "Zopiclone", "dose": "7.5mg", "appearance": "ËóçËâ≤ÂúìÂΩ¢", "indication": "Â§±Áú†", "warning": "ÂèØËÉΩÊúâÈáëÂ±¨Âë≥", "default_usage": "QD_bedtime"},
    ],
    "Cardiac": [
        {"code": "BC55556666", "name_en": "Aspirin", "name_zh": "ÈòøÊñØÂåπÈùà", "generic": "ASA", "dose": "100mg", "appearance": "ÁôΩËâ≤ÂúìÂΩ¢", "indication": "È†êÈò≤Ë°ÄÊ†ì", "warning": "ËÉÉÊΩ∞ÁòçÊÇ£ËÄÖÊÖéÁî®", "default_usage": "QD_breakfast_after"},
        {"code": "BC55556667", "name_en": "Plavix", "name_zh": "‰øùÊ†ìÈÄö", "generic": "Clopidogrel", "dose": "75mg", "appearance": "Á≤âÁ¥ÖËâ≤ÂúìÂΩ¢", "indication": "È†êÈò≤Ë°ÄÊ†ì", "warning": "ÊâãË°ìÂâçÈúÄÂÅúËó•", "default_usage": "QD_breakfast_after"},
    ],
    "Anticoagulant": [
        {"code": "BC77778888", "name_en": "Warfarin", "name_zh": "ÂèØÂåñÂáù", "generic": "Warfarin", "dose": "5mg", "appearance": "Á≤âÁ¥ÖËâ≤ÂúìÂΩ¢", "indication": "ÊäóÂáùË°Ä", "warning": "ÈúÄÂÆöÊúüÁõ£Ê∏¨INRÔºåÈÅøÂÖçÊ∑±Á∂†Ëâ≤Ëî¨Ëèú", "default_usage": "QD_bedtime"},
    ],
    "Lipid": [
        {"code": "BC88889999", "name_en": "Lipitor", "name_zh": "Á´ãÊôÆÂ¶•", "generic": "Atorvastatin", "dose": "20mg", "appearance": "ÁôΩËâ≤Ê©¢ÂúìÂΩ¢", "indication": "ÈôçË°ÄËÑÇ", "warning": "ËÇåËÇâÁó†ÁóõÊôÇÈúÄÂõûË®∫", "default_usage": "QD_bedtime"},
        {"code": "BC88889998", "name_en": "Crestor", "name_zh": "ÂÜ†ËÑÇÂ¶•", "generic": "Rosuvastatin", "dose": "10mg", "appearance": "Á≤âÁ¥ÖËâ≤ÂúìÂΩ¢", "indication": "ÈôçË°ÄËÑÇ", "warning": "ÈÅøÂÖçËàáËë°ËêÑÊüöÊ±Å‰ΩµÊúç", "default_usage": "QD_bedtime"},
    ],
}

# V7 Mock-RAG Interface - Enhanced to search using original AND alias
def retrieve_drug_info(drug_name: str) -> dict:
    """RAG Interface: Query drug knowledge base. In production, this calls external APIs."""
    drug_lower = drug_name.lower().strip()
    # V7 Fix: Build list of names to search (alias first, then original)
    names_to_search = [drug_lower]
    if drug_lower in DRUG_ALIASES:
        names_to_search.append(DRUG_ALIASES[drug_lower]) 

    # Search in full database
    for cat, drugs in DRUG_DATABASE.items():
        for drug in drugs:
            name_en_lower = drug.get("name_en", "").lower()
            generic_lower = drug.get("generic", "").lower()
            
            # Use 'found' flag format expected by logical_consistency_check
            for search_name in names_to_search:
                if (search_name in name_en_lower or 
                    search_name in generic_lower or
                    name_en_lower in search_name or
                    generic_lower in search_name):
                    
                    # Adapt to simplified dict format if needed, or return full drug object + found flag
                    result = drug.copy()
                    result["found"] = True
                    return result
            
    return {"found": False, "class": "Unknown", "risk": "Manual Review Required"}

# ============================================================================
# üíä OpenFDA Drug Interaction Checker (Agentic Tool Use)
# ============================================================================
def check_drug_interaction(drug_a, drug_b):
    """
    Query OpenFDA API for potential interactions.
    Demonstrates 'Tool Use' capability of the Agent.
    """
    if not drug_a or not drug_b:
        return "‚ö†Ô∏è Please enter two drug names."
        
    # 1. Normalize Names using Alias Map
    name_a = DRUG_ALIASES.get(drug_a.lower(), drug_a.lower())
    name_b = DRUG_ALIASES.get(drug_b.lower(), drug_b.lower())
    
    print(f"üîé Checking interaction: {name_a} + {name_b}")
    
    # 2. Hardcoded Critical Interactions (Fallback & Demo Safety)
    # OpenFDA responses are complex JSONs; for reliable demo, we prioritize known major risks.
    CRITICAL_PAIRS = {
        ("warfarin", "aspirin"): "üî¥ **MAJOR RISK**: Increased bleeding probability. Monitor INR closely.",
        ("warfarin", "ibuprofen"): "üî¥ **MAJOR RISK**: High bleeding risk (NSAID + Anticoagulant).",
        ("metformin", "contrast_dye"): "‚ö†Ô∏è **WARNING**: Risk of Lactic Acidosis. Hold Metformin 48h before/after procedure.",
        ("lisinopril", "potassium"): "‚ö†Ô∏è **WARNING**: Risk of Hyperkalemia (high potassium).",
        ("sildenafil", "nitroglycerin"): "üî¥ **CONTRAINDICATED**: Fatal hypotension risk. DO NOT COMBINE.",
        ("zolpidem", "alcohol"): "üî¥ **MAJOR RISK**: Severe CNS depression. High fall risk for elderly.",
    }
    
    # Check both orders (a,b) and (b,a)
    if (name_a, name_b) in CRITICAL_PAIRS:
        return CRITICAL_PAIRS[(name_a, name_b)]
    if (name_b, name_a) in CRITICAL_PAIRS:
        return CRITICAL_PAIRS[(name_b, name_a)]
        
    # 3. Live OpenFDA API Call (Agentic Step)
    try:
        import requests
        # Query OpenFDA labeling endpoint
        # Note: OpenFDA doesn't have a direct "interaction checker" endpoint like commercial APIs.
        # We simulate it by searching for Drug A's label containing Drug B's name in 'drug_interactions' section.
        url = f"https://api.fda.gov/drug/label.json?search=openfda.generic_name:{name_a}+AND+drug_interactions:{name_b}&limit=1"
        
        response = requests.get(url, timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            if "results" in data and len(data["results"]) > 0:
                # Found a mention!
                return f"‚ö†Ô∏è **OpenFDA Alert**: The official label for **{name_a.title()}** explicitly mentions interactions with **{name_b.title()}**. Please consult a pharmacist."
            else:
                # Try reverse query
                url_rev = f"https://api.fda.gov/drug/label.json?search=openfda.generic_name:{name_b}+AND+drug_interactions:{name_a}&limit=1"
                response_rev = requests.get(url_rev, timeout=5)
                if response_rev.status_code == 200 and "results" in response_rev.json():
                    return f"‚ö†Ô∏è **OpenFDA Alert**: The official label for **{name_b.title()}** explicitly mentions interactions with **{name_a.title()}**."
        
        return "‚úÖ No obvious interaction found in OpenFDA summary labels. (Always consult a pharmacist)"
        
    except Exception as e:
        print(f"OpenFDA API Error: {e}")
        return "‚ö†Ô∏è API unavailable. Please check manually."

def logical_consistency_check(extracted_data):
    """
    Neuro-Symbolic Logic Check (Hybrid Architecture)
    V6: Now integrates with Mock-RAG interface for drug validation
    """
    issues = []
    # 1. Age Check
    try:
        age_val = extracted_data.get("patient", {}).get("age", 0)
        age = int(age_val)
        if age < 0 or age > 120:
             issues.append(f"Invalid age: {age}")
        # V6 Fix: Pediatric Guardrail
        if age < 18:
             issues.append(f"Pediatric age ({age}) requires manual review")
        # Geriatric High Dose Check
        if age > 80:
            dose = extracted_data.get("drug", {}).get("dose", "")
            # V6.3 FIX: Find number BEFORE unit (mg/g/mcg), not first number
            # Fixes: "2 tablets of 500mg" was parsed as "2" instead of "500"
            import re
            dose_match = re.search(r'(\d+)\s*(?:mg|g|mcg)', dose, re.IGNORECASE)
            
            if dose_match:
                dose_value = int(dose_match.group(1))
                # Unit conversion: if 'g' (not mg), multiply by 1000
                if re.search(r'\d+\s*g(?!m)', dose, re.IGNORECASE):
                    dose_value *= 1000
                if dose_value >= 1000:
                    issues.append(f"Geriatric High Dose Warning: {age}yr + {dose}")
    except:
        pass

    # 2. Dosage Format Check
    try:
        dose = str(extracted_data.get("drug", {}).get("dose", ""))
        # V6 Fix: Expanded Regex
        if dose and not re.search(r'\d+\s*(mg|ml|g|mcg|ug|tablet|capsule|pill|cap|tab|drops|gtt)', dose, re.IGNORECASE):
            issues.append(f"Abnormal dosage format: {dose}")
    except:
        pass
    
    # 3. V6 NEW: Mock-RAG Drug Validation
    try:
        drug_name = extracted_data.get("drug", {}).get("name", "") or extracted_data.get("drug", {}).get("name_en", "")
        if drug_name:
            drug_info = retrieve_drug_info(drug_name)
            if not drug_info.get("found", False):
                issues.append(f"Drug not in knowledge base: {drug_name}")
    except:
        pass  # RAG failures shouldn't block the pipeline
        
    return issues

def json_to_elderly_speech(result_json):
    """Generates the TTS script for SilverGuard (V6: Prioritizes LLM output)"""
    try:
        # V6: Priority 1 - Use LLM-generated silverguard_message if available
        if "silverguard_message" in result_json:
            return result_json["silverguard_message"]
        
        # Priority 2: Rule-based fallback
        safety = result_json.get("safety_analysis", {})
        data = result_json.get("extracted_data", {})
        status = safety.get("status", "UNKNOWN")
        reasoning = safety.get("reasoning", "")
        drug_name = data.get("drug", {}).get("name", "Ëó•Áâ©")
        
        if status == "HIGH_RISK":
            return f"ÈòøÂ¨§Ê≥®ÊÑèÂñîÔºÅÈÄôÂÄãËó•ÊòØ{drug_name}„ÄÇAIÁôºÁèæÊúâÈ¢®Èö™Ôºö{reasoning}„ÄÇË´ãÂÖà‰∏çË¶ÅÂêÉÔºåË∂ïÂø´ÊâìÈõªË©±ÂïèËó•Â∏´„ÄÇÊ≥®ÊÑèÂÆâÂÖ®ÂñîÔºÅ"
        elif status == "HUMAN_REVIEW_NEEDED":
            return f"ÈòøÂ¨§ÔºåÈÄôÂÄãËó•ÊòØ{drug_name}„ÄÇ‰ΩÜÊòØÊàëÁúã‰∏çÊ∏ÖÊ•öÔºåÁÇ∫‰∫ÜÂÆâÂÖ®ÔºåË´ã‰Ω†ÊãøÁµ¶Ëó•Â∏´ÁúãÔºåÂÖà‰∏çË¶ÅËá™Â∑±ÂêÉÂñî„ÄÇ"
        else: # SAFE
            usage = data.get("usage", "ÁÖßÈÜ´Âõë‰ΩøÁî®")
            return f"ÈòøÂ¨§ÔºåÈÄôÊòØ{drug_name}„ÄÇAIÊ™¢Êü•Ê≤íÂïèÈ°å„ÄÇ‰ΩøÁî®ÊñπÊ≥ïÊòØÔºö{usage}„ÄÇË´ãÂÆâÂøÉ‰ΩøÁî®„ÄÇ"
    except:
        return "Á≥ªÁµ±ÂøôÁ¢å‰∏≠ÔºåË´ãÁ®çÂæåÂÜçË©¶„ÄÇ"

@spaces.GPU(duration=120)
def run_inference(image, patient_notes=""):
    """
    Main inference function.
    - image: PIL Image of drug bag
    - patient_notes: Optional text from MedASR transcription (e.g., "I'm allergic to aspirin")
    """
    # 0. Input Gate (V6)
    is_clear, quality_msg = check_image_quality(image)
    if not is_clear:
        return "REJECTED_INPUT", {"error": quality_msg}, "ÈòøÂ¨§ÔºåÁÖßÁâáÂ§™Ê®°Á≥ä‰∫ÜÔºåÊàëÁúã‰∏çÂ§™Ê∏ÖÊ•ö„ÄÇË´ãÈáçÊñ∞Êãç‰∏ÄÂºµÊ∏ÖÊ•ö‰∏ÄÈªûÁöÑÂñî„ÄÇ", None

    if model is None:
        return "Model Error", {"error": "Model not loaded properly. Check logs."}, "System Error", None
    
    # V8 NEW: Build patient context from voice notes
    patient_context = ""
    if patient_notes and patient_notes.strip():
        patient_context = f"\n\n**CRITICAL Patient Note (from voice input)**: \"{patient_notes}\"\n"
        patient_context += "‚ö†Ô∏è Cross-check this note against the prescription. Flag HIGH_RISK if any drug in the image matches the patient's stated allergies or conditions.\n"
    
    # 1. Enhanced Prompting (V6.3: Synced with Kaggle - Full Prompt with JSON Example)
    prompt = (
        "You are 'AI Pharmacist Guardian', a **meticulous and risk-averse** clinical pharmacist in Taiwan. "
        "You prioritize patient safety above all else. When uncertain, you MUST flag for human review rather than guessing. "
        "Your patient is an elderly person (65+) who may have poor vision.\n\n"
        f"{patient_context}"  # V8: Inject patient notes from MedASR
        "Task:\n"
        "1. Extract: Patient info, Drug info (English name + Chinese function), Usage.\n"
        "2. Safety Check: Cross-reference AGS Beers Criteria 2023. Flag HIGH_RISK if age>80 + high dose.\n"
        "3. SilverGuard: Add a warm message in spoken Taiwanese Mandarin (Âè£Ë™ûÂåñÂè∞Âºè‰∏≠Êñá).\n\n"
        "Output Constraints:\n"
        "- Return ONLY a valid JSON object.\n"
        "- 'safety_analysis.reasoning' MUST be in Traditional Chinese (ÁπÅÈ´î‰∏≠Êñá).\n"
        "- Add 'silverguard_message' field using the persona of a caring grandchild (Ë≤ºÂøÉÊôöËº©).\n\n"
        "JSON Example:\n"
        "{\"extracted_data\": {...}, \"safety_analysis\": {\"status\": \"HIGH_RISK\", "
        "\"reasoning\": \"ÁóÖÊÇ£88Ê≠≤ÔºåGlucophage 2000mg ÂäëÈáèÈÅéÈ´òÔºå‰æù Beers Criteria ÊÅêÊúâÈ¢®Èö™„ÄÇ\"}, "
        "\"silverguard_message\": \"ÈòøÂ¨§Ôºå‰øÆ‰ΩÜÂπæÂíßÔºÅÈÄôÂåÖËó•ÂäëÈáèÂ§™Èáç‰∫ÜÔºåÂÖà‰∏çË¶ÅÂêÉÔºåË∂ïÂø´ÂïèËó•Â∏´ÂñîÔºÅ\"}"
    )
    inputs = processor(text=prompt, images=image, return_tensors="pt").to(model.device)
    
    # üî• V6.1 FIX: Ë®òÈåÑËº∏ÂÖ•Èï∑Â∫¶ÔºåÁî®ÊñºÂàáÈô§ Input Echoing
    input_len = inputs.input_ids.shape[1]
    
    # 2. Generation
    # V7.1 FIX: Use same sampling strategy as Kaggle for consistency
    # temperature=0.6 allows slight variation while remaining stable
    with torch.inference_mode():
        generate_ids = model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=True,       # V7.1: Match Kaggle (was False)
            temperature=0.6,      # V7.1: Balanced creativity
            top_p=0.9,            # Nucleus sampling for quality
        )
    
    # üî•üî•üî• V6.1 Ê†∏ÂøÉ‰øÆÂæ©ÔºöÂè™Ëß£Á¢ºÊñ∞ÁîüÊàêÁöÑ tokens üî•üî•üî•
    generated_tokens = generate_ids[:, input_len:]
    response = processor.batch_decode(generated_tokens, skip_special_tokens=True)[0]
    
    # 4. Parsing JSON using V6.1 Stack-based Last-In-First-Check Approach
    import ast
    
    def parse_model_output(response_text):
        """V6.1: Stack-based parser, checks LAST JSON block first (synced from Kaggle)"""
        # Ê∏ÖÁêÜ Markdown
        response_text = re.sub(r'```json\s*', '', response_text)
        response_text = re.sub(r'```', '', response_text)
        response_text = response_text.strip()
        
        # Â∞ãÊâæÊâÄÊúâÁöÑÂ§ßÊã¨ËôüÈÖçÂ∞ç (Stack-based)
        matches = []
        stack = []
        start_index = -1
        
        for i, char in enumerate(response_text):
            if char == '{':
                if not stack:
                    start_index = i
                stack.append(char)
            elif char == '}':
                if stack:
                    stack.pop()
                    if not stack and start_index >= 0:
                        matches.append(response_text[start_index:i+1])

        if not matches:
            return {"raw_output": response_text, "error": "No JSON structure found"}

        # ÂÄíÂ∫èÂòóË©¶Ëß£Êûê (Last-In-First-Check)
        for json_str in reversed(matches):
            # Strategy 1: Standard JSON with boolean fix
            try:
                fixed = json_str.replace("True", "true").replace("False", "false").replace("None", "null")
                return json.loads(fixed)
            except json.JSONDecodeError:
                pass
            
            # Strategy 2: ast.literal_eval for Python dict syntax
            try:
                eval_str = json_str.replace("true", "True").replace("false", "False").replace("null", "None")
                python_obj = ast.literal_eval(eval_str)
                if isinstance(python_obj, dict):
                    return python_obj
            except (ValueError, SyntaxError):
                pass
            
            # Strategy 3: Brute-force quote replacement
            try:
                brutal_fix = json_str.replace("'", '"')
                brutal_fix = brutal_fix.replace("True", "true").replace("False", "false").replace("None", "null")
                return json.loads(brutal_fix)
            except json.JSONDecodeError:
                pass
        
        return {"raw_output": response_text[:200], "error": "All JSON parsing strategies failed"}
    
    result_json = parse_model_output(response)
    
    # V6 Fix: Neuro-Symbolic Logic Injection
    # We perform the logic check here and append issues to safety analysis if found
    if "extracted_data" in result_json:
        logic_issues = logical_consistency_check(result_json["extracted_data"])
        if logic_issues:
            # Force status to HUMAN_REVIEW_NEEDED if logic fails
            if "safety_analysis" not in result_json:
                result_json["safety_analysis"] = {}
            result_json["safety_analysis"]["status"] = "HUMAN_REVIEW_NEEDED"
            current_reasoning = result_json["safety_analysis"].get("reasoning", "")
            result_json["safety_analysis"]["reasoning"] = f"‚ö†Ô∏è Logic Issues Detected: {'; '.join(logic_issues)}. " + current_reasoning

    # OOD Check
    if not check_is_prescription(response):
         if "safety_analysis" not in result_json:
                result_json["safety_analysis"] = {}
         result_json["safety_analysis"]["status"] = "LOW_CONFIDENCE"
         result_json["safety_analysis"]["reasoning"] = "‚ö†Ô∏è Content does not look like a standard prescription."
        
    # 5. SilverGuard Processing
    final_status = result_json.get("safety_analysis", {}).get("status", "UNKNOWN")
    speech_text = json_to_elderly_speech(result_json)
    
    # ========================================================================
    # 6. V7.2 Hybrid TTS: Online (gTTS) ‚Üí Offline (pyttsx3) ‚Üí Visual-Only
    # ========================================================================
    # Addresses "Offline" claim in promotional materials
    # In production rural clinics, internet may be intermittent
    # ========================================================================
    audio_path = None
    tts_mode = "none"
    
    # Clean text for TTS (remove emojis)
    clean_text = speech_text.replace("‚ö†Ô∏è", "Ê≥®ÊÑè").replace("‚úÖ", "").replace("üü°", "")
    clean_text = clean_text.replace("üëâ", "").replace("üìÖ", "").replace("üíä", "")
    
    # === Tier 1: Try gTTS (requires internet, best quality) ===
    try:
        import socket
        # Quick network check (1 second timeout)
        socket.setdefaulttimeout(1)
        socket.create_connection(("www.google.com", 80))
        
        from gtts import gTTS
        import tempfile
        tts = gTTS(text=clean_text, lang='zh-TW', slow=True)
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
            audio_path = f.name
        tts.save(audio_path)
        tts_mode = "online"
        print("üîä TTS: Using gTTS (Online Mode)")
    except Exception as e:
        print(f"‚ö†Ô∏è gTTS failed (likely offline): {e}")
        
        # === Tier 2: Try pyttsx3 (offline, requires OS voice packs) ===
        try:
            import pyttsx3
            import tempfile
            engine = pyttsx3.init()
            # Try to find Chinese voice
            voices = engine.getProperty('voices')
            for voice in voices:
                if 'zh' in voice.id.lower() or 'chinese' in voice.name.lower():
                    engine.setProperty('voice', voice.id)
                    break
            
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                audio_path = f.name
            engine.save_to_file(clean_text, audio_path)
            engine.runAndWait()
            tts_mode = "offline"
            print("üîä TTS: Using pyttsx3 (Offline Mode)")
        except Exception as e2:
            print(f"‚ö†Ô∏è pyttsx3 failed: {e2}")
            
            # === Tier 3: Visual-Only Fallback (always works) ===
            audio_path = None
            tts_mode = "visual_only"
            print("üìÑ TTS: Visual-Only Mode (No audio available)")
    
    # Add TTS mode indicator to result for transparency
    result_json["_tts_mode"] = tts_mode
    
    return final_status, result_json, speech_text, audio_path

# ============================================================================
# üñ•Ô∏è Gradio Interface
# ============================================================================
custom_css = """
#risk-header {color: #d32f2f; font-weight: bold; font-size: 1.2em;}
"""

with gr.Blocks(theme=gr.themes.Soft(), css=custom_css) as demo:
    gr.Markdown("# üè• AI Pharmacist Guardian + SilverGuard (Live Demo)")
    gr.Markdown("> **MedGemma Impact Challenge** | *Powered by Google MedGemma 1.5-4B + **MedASR** (Voice)*")
    
    # V7.1 NEW: Fast Mode Disclaimer (ZeroGPU timeout limitation)
    gr.Markdown(
        "> ‚ö° **Fast Mode**: This demo runs single-pass inference for speed. "
        "Full Agentic Retry Loop (self-correction) is available in the [Kaggle Notebook](https://kaggle.com).\n\n"
        "> üîä **Hybrid TTS**: Voice uses gTTS (online) with pyttsx3 (offline) fallback for rural deployment.\n\n"
        "> üé§ **MedASR Voice Log**: Family/Caregiver can log patient allergies in English. "
        "Example: *'My grandmother is allergic to Aspirin and has kidney disease.'*"
    )
    
    with gr.Tabs():
        # TAB 1: Main Vision Agent
        with gr.TabItem("üè• AI Pharmacist Guardian"):
            with gr.Row():
                with gr.Column(scale=1):
                    input_img = gr.Image(type="pil", label="üì∏ Upload Drug Bag Photo")
                    
                    # V8 NEW: MedASR Voice Input (Reframed as Caregiver Tool)
                    gr.Markdown("### üé§ Caregiver Voice Log (Optional)")
                    gr.Markdown("*For family/pharmacist to log patient info. Speak clearly in English for best accuracy.*")
                    voice_input = gr.Audio(sources=["microphone"], type="filepath", label="üéôÔ∏è Record caregiver note (e.g., 'Patient is allergic to Aspirin')")
                    transcription_display = gr.Textbox(label="üìù Transcription (Google MedASR)", interactive=False, placeholder="Caregiver voice note will appear here...")
                    
                    btn = gr.Button("üîç Analyze & Safety Check", variant="primary", size="lg")
                    gr.Markdown("### üí° How to test:\n1. Upload a drug bag photo.\n2. (Optional) Record a voice note as *caregiver* describing patient's allergies.\n3. AI will cross-check the prescription against the patient's conditions.")
                
                with gr.Column(scale=1):
                    # Status Banner
                    status_output = gr.Textbox(label="üõ°Ô∏è Safety Status", elem_id="risk-header")
                    
                    # SilverGuard Output
                    silver_output = gr.Textbox(label="üëµ SilverGuard (Elder-Friendly Script)", lines=3)
                    
                    # V6.3 NEW: Audio playback for SilverGuard
                    audio_output = gr.Audio(label="üîä Voice Alert (Ë´ãÈªûÊí≠Êîæ)")
                    
                    # Raw JSON output (for debug/judges)
                    json_output = gr.JSON(label="üìä Extracted Data & Reasoning Chain")
            
            # --- Tab 1 Event Wiring ---
            # V8 NEW: Wrapper function that transcribes audio then runs inference
            def analyze_with_voice(image, audio_path):
                """
                1. Transcribe voice note using MedASR (if provided)
                2. Run MedGemma inference with image + patient notes
                3. Return all outputs including transcription display
                """
                # Step 1: Transcribe if audio provided
                transcription = ""
                if audio_path:
                    transcription, success = transcribe_audio(audio_path)
                    if success:
                        print(f"üé§ Patient Note: {transcription}")
                    else:
                        transcription = "(Voice transcription failed, proceeding without patient note)"
                
                # Step 2: Run MedGemma inference with patient notes
                status, json_out, silver, audio = run_inference(image, patient_notes=transcription)
                
                # Return 5 outputs: transcription + original 4
                return transcription, status, json_out, silver, audio
            
            btn.click(
                fn=analyze_with_voice, 
                inputs=[input_img, voice_input], 
                outputs=[transcription_display, status_output, json_output, silver_output, audio_output]
            )
            
            # Feedback Loop (Reinforcement Learning)
            gr.Markdown("---")
            gr.Markdown("### üìä Help Improve This Model")
            with gr.Row():
                btn_correct = gr.Button("‚úÖ Correct", size="sm")
                btn_error = gr.Button("‚ùå Error", size="sm")
            feedback_output = gr.Textbox(label="RLHF Feedback Status", interactive=False)
            gr.Markdown(
                "*‚ÑπÔ∏è Pharmacist feedback is collected to fine-tune future versions via "
                "**RLHF (Reinforcement Learning from Human Feedback)**. "
                "Your corrections help protect the next patient.*"
            )
            
            # Wired up inputs: Image + JSON Output + Feedback Type
            btn_correct.click(
                fn=lambda img, out: log_feedback(img, out, "POSITIVE_ACCURATE"), 
                inputs=[input_img, json_output], 
                outputs=feedback_output
            )
            btn_error.click(
                fn=lambda img, out: log_feedback(img, out, "NEGATIVE_ERROR"), 
                inputs=[input_img, json_output], 
                outputs=feedback_output
            )

        # TAB 2: Agentic Tool Use (OpenFDA)
        with gr.TabItem("üíä Agentic Drug Interaction Checker"):
            gr.Markdown("### üîó OpenFDA Agentic Tool Demo")
            gr.Markdown(
                "> Demonstrates the Agent's ability to **call external APIs** for knowledge retrieval. "
                "Enter two drugs to check for official FDA-labeled interactions."
            )
            with gr.Row():
                with gr.Column():
                    drug_a_input = gr.Textbox(label="Drug A (e.g., Warfarin)", placeholder="Enter first drug name")
                    drug_b_input = gr.Textbox(label="Drug B (e.g., Aspirin)", placeholder="Enter second drug name")
                    chk_btn = gr.Button("üîç Check Interactions (Call OpenFDA API)", variant="secondary")
                with gr.Column():
                    interaction_output = gr.Markdown(label="Interaction Result")
            
            # Example Buttons
            gr.Markdown("### üß™ Quick Examples:")
            with gr.Row():
                ex_btn1 = gr.Button("Warfarin + Aspirin")
                ex_btn2 = gr.Button("Metformin + Contrast_Dye")
                ex_btn3 = gr.Button("Sildenafil + Nitroglycerin")
            
            # Wiring
            chk_btn.click(check_drug_interaction, inputs=[drug_a_input, drug_b_input], outputs=interaction_output)
            
            # Example handlers
            ex_btn1.click(lambda: ("Warfarin", "Aspirin"), outputs=[drug_a_input, drug_b_input])
            ex_btn2.click(lambda: ("Metformin", "Contrast_Dye"), outputs=[drug_a_input, drug_b_input])
            ex_btn3.click(lambda: ("Sildenafil", "Nitroglycerin"), outputs=[drug_a_input, drug_b_input])

# ============================================================================
# üñ•Ô∏è Gradio Interface
# ============================================================================
# custom_css = """
# #risk-header {color: #d32f2f; font-weight: bold; font-size: 1.2em;}
# """

# with gr.Blocks(theme=gr.themes.Soft(), css=custom_css) as demo:
#     gr.Markdown("# üè• AI Pharmacist Guardian + SilverGuard (Live Demo)")
#     gr.Markdown("> **MedGemma Impact Challenge** | *Powered by Google MedGemma 1.5-4B + **MedASR** (Voice)*")
    
#     # V7.1 NEW: Fast Mode Disclaimer (ZeroGPU timeout limitation)
#     gr.Markdown(
#         "> ‚ö° **Fast Mode**: This demo runs single-pass inference for speed. "
#         "Full Agentic Retry Loop (self-correction) is available in the [Kaggle Notebook](https://kaggle.com).\n\n"
#         "> üîä **Hybrid TTS**: Voice uses gTTS (online) with pyttsx3 (offline) fallback for rural deployment.\n\n"
#         "> üé§ **MedASR Voice Log**: Family/Caregiver can log patient allergies in English. "
#         "Example: *'My grandmother is allergic to Aspirin and has kidney disease.'*"
#     )
    
#     with gr.Row():
#         with gr.Column(scale=1):
#             input_img = gr.Image(type="pil", label="üì∏ Upload Drug Bag Photo")
            
#             # V8 NEW: MedASR Voice Input (Reframed as Caregiver Tool)
#             gr.Markdown("### üé§ Caregiver Voice Log (Optional)")
#             gr.Markdown("*For family/pharmacist to log patient info. Speak clearly in English for best accuracy.*")
#             voice_input = gr.Audio(sources=["microphone"], type="filepath", label="üéôÔ∏è Record caregiver note (e.g., 'Patient is allergic to Aspirin')")
#             transcription_display = gr.Textbox(label="üìù Transcription (Google MedASR)", interactive=False, placeholder="Caregiver voice note will appear here...")
            
#             btn = gr.Button("üîç Analyze & Safety Check", variant="primary", size="lg")
#             gr.Markdown("### üí° How to test:\n1. Upload a drug bag photo.\n2. (Optional) Record a voice note as *caregiver* describing patient's allergies.\n3. AI will cross-check the prescription against the patient's conditions.")
        
#         with gr.Column(scale=1):
#             # Status Banner
#             status_output = gr.Textbox(label="üõ°Ô∏è Safety Status", elem_id="risk-header")
            
#             # SilverGuard Output
#             silver_output = gr.Textbox(label="üëµ SilverGuard (Elder-Friendly Script)", lines=3)
            
#             # V6.3 NEW: Audio playback for SilverGuard
#             audio_output = gr.Audio(label="üîä Voice Alert (Ë´ãÈªûÊí≠Êîæ)")
            
#             # Technical Debug
#             with gr.Accordion("üß† View Agent Reasoning (JSON)", open=False):
#                 json_output = gr.JSON(label="Full Agent Output")
            
#             # === Data Flywheel: Feedback Mechanism (MLOps) ===
#             gr.Markdown("---")
#             gr.Markdown("### üìä Help Improve This Model")
#             with gr.Row():
#                 btn_correct = gr.Button("üëç Accurate (Á¢∫Ë™çÁÑ°Ë™§)", variant="secondary", size="sm")
#                 btn_error = gr.Button("üëé Report Error (ÂõûÂ†±ÈåØË™§)", variant="stop", size="sm")
#             feedback_output = gr.Textbox(label="Feedback Status", visible=True, interactive=False)
#             gr.Markdown(
#                 "*‚ÑπÔ∏è Pharmacist feedback is collected to fine-tune future versions via "
#                 "**RLHF (Reinforcement Learning from Human Feedback)**. "
#                 "Your corrections help protect the next patient.*"
#             )
            
#     # === Button Event Handlers ===
#     # === Button Event Handlers ===
    
#     # V7.3 S-Tier MLOps: Initializing Hugging Face Dataset Saver (Real Data Flywheel)
#     hf_saver = None
#     try:
#         if HF_TOKEN:
#             # Automatic dataset creation: "medgemma-impact-feedback"
#             hf_saver = gr.HuggingFaceDatasetSaver(HF_TOKEN, "medgemma-impact-feedback", private=True)
#             print("‚úÖ MLOps: Connected to Hugging Face Dataset for feedback loop.")
#         else:
#             print("‚ö†Ô∏è MLOps: HF_TOKEN not found, feedback will be local only.")
#     except Exception as e:
#         print(f"‚ö†Ô∏è MLOps: Failed to initialize HF Saver: {e}")

#     def log_feedback(image, model_json, feedback_type):
#         """
#         Log feedback for RLHF pipeline
#         - V7.3: Tries to save REAL data to Hugging Face Dataset
#         - Fallback: Returns log message
#         """
#         import datetime
#         timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
#         status_msg = f"‚úÖ Feedback logged at {timestamp}: {feedback_type}."
        
#         # 1. Try to save to HF Dataset
#         if hf_saver:
#             try:
#                 # Structure: [Timestamp, Feedback, Model Output, Image]
#                 # Note: Image must be saved last usually, logic depends on Saver
#                 # Simplified for demo: Just saving text data if image fails, or try calling flag()
#                 # flag() signature: flag(flag_data, flag_option=None, username=None)
#                 hf_saver.flag([image, json.dumps(model_json, ensure_ascii=False), feedback_type, timestamp])
#                 status_msg += " (üíæ Saved to HF Dataset)"
#             except Exception as e:
#                 print(f"HF Save Error: {e}")
#                 status_msg += " (‚ö†Ô∏è Cloud save failed, logged locally)"
        
#         return status_msg
    
#     # V8 NEW: Wrapper function that transcribes audio then runs inference
#     def analyze_with_voice(image, audio_path):
#         """
#         1. Transcribe voice note using MedASR (if provided)
#         2. Run MedGemma inference with image + patient notes
#         3. Return all outputs including transcription display
#         """
#         # Step 1: Transcribe if audio provided
#         transcription = ""
#         if audio_path:
#             transcription, success = transcribe_audio(audio_path)
#             if success:
#                 print(f"üé§ Patient Note: {transcription}")
#             else:
#                 transcription = "(Voice transcription failed, proceeding without patient note)"
        
#         # Step 2: Run MedGemma inference with patient notes
#         status, json_out, silver, audio = run_inference(image, patient_notes=transcription)
        
#         # Return 5 outputs: transcription + original 4
#         return transcription, status, json_out, silver, audio
    
#     btn.click(
#         fn=analyze_with_voice, 
#         inputs=[input_img, voice_input], 
#         outputs=[transcription_display, status_output, json_output, silver_output, audio_output]
#     )
    
#     # Wired up inputs: Image + JSON Output + Feedback Type
#     btn_correct.click(
#         fn=lambda img, out: log_feedback(img, out, "POSITIVE_ACCURATE"), 
#         inputs=[input_img, json_output], 
#         outputs=feedback_output
#     )
#     btn_error.click(
#         fn=lambda img, out: log_feedback(img, out, "NEGATIVE_ERROR"), 
#         inputs=[input_img, json_output], 
#         outputs=feedback_output
#     )

if __name__ == "__main__":
    demo.launch()
