{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dcbfa8",
   "metadata": {},
   "source": [
    "# üõ°Ô∏è SilverGuard: Agentic Workflow for Medication Safety\n",
    "### Impact Challenge 2026 Submission | Team Omni-Nexus\n",
    "\n",
    "**\"Protecting the elderly from medication errors with Edge-AI and System 2 Thinking.\"**\n",
    "\n",
    "SilverGuard acts as a **Clinical Decision Support System (CDSS)** specifically designed for elderly patients. Unlike standard LLMs, it employs an **Agentic Workflow** with self-correction, RAG-grounding, and safety critics to ensure medical-grade reliability.\n",
    "\n",
    "### üé• [Project Video Demo](https://youtu.be/INSERT_YOUR_YOUTUBE_LINK_HERE) | üåê [Hugging Face Live App](https://huggingface.co/spaces/markwang941108/SilverGuard-V1)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß¨ Act II: The Synthetic Data Factory (V17 Fusion)\n",
    "To solve the data scarcity problem for Taiwan-specific drug bags, we built a **Physics-Informed Synthetic Data Engine**. \n",
    "It simulates:\n",
    "- 3D Pill Rendering (Shape/Color/Lighting)\n",
    "- Optical Stress (Blur/Glare/Crumpling)\n",
    "- Hard Negatives (LASA - Look-Alike Sound-Alike pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Data Generation Engine Core\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def apply_optical_stress(img, severity=0.5):\n",
    "    \"\"\"[Layer 2: Optics] Simulating elderly vision/poor camera focus\"\"\"\n",
    "    if severity == 0: return img\n",
    "    radius = severity * 2.0\n",
    "    if radius > 0:\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(radius*0.8, radius*1.2)))\n",
    "    return img\n",
    "\n",
    "# Visualize a Sample (Robust Loader)\n",
    "try:\n",
    "    # Try loading from local assets (if uploaded)\n",
    "    img_path = \"assets/hero_image.jpg\"\n",
    "    if not os.path.exists(img_path): \n",
    "        # Fallback: Generate a dummy sample for notebook demo\n",
    "        img = Image.new('RGB', (400, 300), color = (73, 109, 137))\n",
    "        d = ImageDraw.Draw(img)\n",
    "        d.text((10,10), \"SilverGuard Synthetic Data Sample\", fill=(255,255,0))\n",
    "        d.rectangle([50, 50, 150, 150], fill=\"white\")\n",
    "        d.text((55, 60), \"Pill\", fill=\"black\")\n",
    "    else:\n",
    "        img = Image.open(img_path)\n",
    "    \n",
    "    # Apply Physics Simulation\n",
    "    processed = apply_optical_stress(img, severity=0.8)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1); plt.imshow(img); plt.title(\"Clean Render\")\n",
    "    plt.subplot(1, 2, 2); plt.imshow(processed); plt.title(\"Sim2Real (Optical Stress)\")\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Visualization skipped: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üñºÔ∏è Sample Outputs (V17 Compliance)\n",
    "We generate high-risk scenarios (e.g., Warfarin vs Aspirin) to train the Safety Critic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Act III: LoRA Fine-Tuning Strategy\n",
    "We fine-tuned **Google MedGemma 1.5-4B** using QLoRA to adapt it to Taiwanese medical visuals and Chinese instructions.\n",
    "\n",
    "**Key Configuration:**\n",
    "- **Target Modules**: All Linear Layers (`q_proj`, `k_proj`, `v_proj`, `o_proj`...)\n",
    "- **Rank (r)**: 16\n",
    "- **Alpha**: 32\n",
    "- **Precision**: 4-bit NormalFloat (NF4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r=16, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"down_proj\", \"q_proj\", \"k_proj\", \"up_proj\", \"gate_proj\", \"o_proj\", \"v_proj\"]\n",
    ")\n",
    "print(\"üß† LoRA Config Loaded: Optimized for MedGemma 1.5 4B\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Act IV: The Agentic Workflow (System 2 Thinking)\n",
    "This is the core innovation. Instead of a single VLM pass, we implement a **Self-Correcting Loop**:\n",
    "1. **Input Gate**: Rejects blurry images.\n",
    "2. **Agentic Loop**: \n",
    "   - **Try 1 (Creative)**: Temp 0.6. Fast intuition.\n",
    "   - **Try 2 (Strict)**: Temp 0.2. Usage of **RAG Tools** and **Safety Critics**.\n",
    "3. **Safety Critic**: A Regex+Logic layer that intercepts hallucinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ°Ô∏è The Safety Critic Tool (Battlefield V17)\n",
    "import re\n",
    "\n",
    "def safety_critic_tool(json_output):\n",
    "    \"\"\"Reflexion Module: Checks for hallucinations and critical interactions\"\"\"\n",
    "    try:\n",
    "        data = json_output if isinstance(json_output, dict) else json.loads(json_output)\n",
    "        # Extract & Clean name\n",
    "        raw = data.get('extracted_data', {}).get('drug', {}).get('name', '')\n",
    "        clean = re.sub(r'\\s*\\d+\\.?\\d*\\s*(mg|g|mcg)\\b', '', raw, flags=re.IGNORECASE).strip()\n",
    "        \n",
    "        # Rule: Conflict Check\n",
    "        if 'Warfarin' in clean and 'Aspirin' in clean:\n",
    "             return False, 'CRITICAL INTERACTION: Warfarin + Aspirin'\n",
    "             \n",
    "        return True, 'Logic Sound'\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ The Agentic Inference Loop (Simplified Trace)\n",
    "def agentic_inference_demo(mock_fail=True):\n",
    "    MAX_RETRIES = 1\n",
    "    print(f\"\\n{'='*40}\\nüõ°Ô∏è AGENTIC PIPELINE STARTED\\n{'='*40}\")\n",
    "    \n",
    "    for try_num in range(MAX_RETRIES + 1):\n",
    "        temp = 0.6 if try_num == 0 else 0.2\n",
    "        print(f\"\\nüîÑ [Step {try_num+1}] Generating... (Temp: {temp})\")\n",
    "        \n",
    "        if try_num == 0 and mock_fail:\n",
    "            print(\"   üß† Strategy: Creative Mode\")\n",
    "            print(\"   ‚ùå Critic: Hard Rule Triggered (Dosage 5000mg impossible)\")\n",
    "            print(\"   ‚ö†Ô∏è Validation Failed. Initiating Self-Correction...\")\n",
    "            continue\n",
    "            \n",
    "        print(\"   üß† Strategy: Strict Logic Mode (System 2)\")\n",
    "        print(\"   üõ†Ô∏è Tool Use: RAG Knowledge Injection (Matches: 'Glucophage')\")\n",
    "        print(\"   ‚úÖ Logic Check Passed!\")\n",
    "        print(\"   ‚úÖ Safety Critic Passed!\")\n",
    "        return {\"status\": \"SUCCESS\", \"reasoning\": \"Corrected dosage to standard 500mg\"}\n",
    "\n",
    "agentic_inference_demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
